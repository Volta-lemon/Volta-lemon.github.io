<?xml version="1.0" encoding="utf-8"?>
<search> 
  
  
    
    <entry>
      <title>基于大模型的文本内容智能评判</title>
      <link href="/post/1.html"/>
      <url>/post/1.html</url>
      
        <content type="html"><![CDATA[<p><a href="https://www.datafountain.cn/competitions/1032">https://www.datafountain.cn/competitions/1032</a><br>赛题背景：<br>大模型作为人工智能领域的热点技术，已在众多垂直行业中展现出巨大的应用潜能。然而，随着其应用范围的不断拓宽，针对大模型的评测需求也日趋复杂化、个性化，这一趋势对现有的评判技术提出了严峻挑战。<br>在文本生成领域，由于信息的多样性、主观性，以及评价标准的复杂性，传统自动化评估方法效果较差，灵活性不足，而人工评价方式效率低下，成本高昂，难以满足当前大规模的评判需求。因此，如何运用自动化、智能化的手段，实现对文本内容的高效评判，成为了业界亟待解决的问题。<br>在此背景下，本赛题以“基于大模型的文本内容智能评判”作为主题，旨在借助大模型强大的语义理解能力和泛化能力，应对不同领域和场景的评判需求，同时精准对齐人类专家的评判标准，进一步提升评判的准确性和可靠性。</p><p>赛题任务：<br>本赛题主要考察文本自动评判任务，参赛者需要利用大模型技术，构建一个智能评判模型，同时具备客观题目、创作题目的评判能力。其中，客观题目需结合参考答案作出评判，创作题目需对齐人类专家的主观评分，评判维度涉及流畅性、规范性。</p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 封装对象</span><span class="token keyword">class</span> <span class="token class-name">DataObject</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> data_id<span class="token punctuation">,</span> creation_requirements<span class="token punctuation">,</span> content<span class="token punctuation">,</span> evaluation_dimension<span class="token punctuation">,</span> score<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>data_id <span class="token operator">=</span> data_id  <span class="token comment" spellcheck="true"># 数据编号</span>        self<span class="token punctuation">.</span>creation_requirements <span class="token operator">=</span> creation_requirements  <span class="token comment" spellcheck="true"># 创作要求（仅规范性数据包含）/选择题题目</span>        self<span class="token punctuation">.</span>content <span class="token operator">=</span> content  <span class="token comment" spellcheck="true"># 待评判内容/选择题答案及模型回复</span>        self<span class="token punctuation">.</span>evaluation_dimension <span class="token operator">=</span> evaluation_dimension  <span class="token comment" spellcheck="true"># 评判维度</span>        self<span class="token punctuation">.</span>score <span class="token operator">=</span> score  <span class="token comment" spellcheck="true"># 分值</span>    <span class="token keyword">def</span> <span class="token function">to_string</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> f<span class="token triple-quoted-string string">"""&lt;data_id>&amp;#123;self.data_id&amp;#125;&lt;/data_id>&lt;creation_requirements>&amp;#123;self.creation_requirements&amp;#125;&lt;/creation_requirements>&lt;content>&amp;#123;self.content&amp;#125;&lt;/content>&lt;evaluation_dimension>&amp;#123;self.evaluation_dimension&amp;#125;&lt;/evaluation_dimension>&lt;score>&amp;#123;self.score&amp;#125;&lt;/score>"""</span><span class="token comment" spellcheck="true"># 示例用法</span>data_object <span class="token operator">=</span> DataObject<span class="token punctuation">(</span>    data_id<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span>    creation_requirements<span class="token operator">=</span><span class="token string">"请描述选择题的题目"</span><span class="token punctuation">,</span>    content<span class="token operator">=</span><span class="token string">"待评判内容/选择题答案及模型回复"</span><span class="token punctuation">,</span>    evaluation_dimension<span class="token operator">=</span><span class="token string">"评判维度"</span><span class="token punctuation">,</span>    score<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 将对象转换为字符串</span>result_string <span class="token operator">=</span> data_object<span class="token punctuation">.</span>to_string<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>result_string<span class="token punctuation">)</span></code></pre><pre><code>&lt;data_id&gt;1&lt;/data_id&gt;&lt;creation_requirements&gt;请描述选择题的题目&lt;/creation_requirements&gt;&lt;content&gt;待评判内容/选择题答案及模型回复&lt;/content&gt;&lt;evaluation_dimension&gt;评判维度&lt;/evaluation_dimension&gt;&lt;score&gt;5&lt;/score&gt;</code></pre><p>​    </p><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd<span class="token keyword">class</span> <span class="token class-name">DataObject</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> data_id<span class="token punctuation">,</span> creation_requirements<span class="token punctuation">,</span> content<span class="token punctuation">,</span> evaluation_dimension<span class="token punctuation">,</span> score<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>data_id <span class="token operator">=</span> data_id  <span class="token comment" spellcheck="true"># 数据编号</span>        self<span class="token punctuation">.</span>creation_requirements <span class="token operator">=</span> creation_requirements  <span class="token comment" spellcheck="true"># 创作要求（仅规范性数据包含）/选择题题目</span>        self<span class="token punctuation">.</span>content <span class="token operator">=</span> content  <span class="token comment" spellcheck="true"># 待评判内容/选择题答案及模型回复</span>        self<span class="token punctuation">.</span>evaluation_dimension <span class="token operator">=</span> evaluation_dimension  <span class="token comment" spellcheck="true"># 评判维度</span>        self<span class="token punctuation">.</span>score <span class="token operator">=</span> score  <span class="token comment" spellcheck="true"># 分值</span>    <span class="token keyword">def</span> <span class="token function">to_string</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> f<span class="token triple-quoted-string string">"""        &lt;evaluation_dimension>&amp;#123;self.evaluation_dimension&amp;#125;&lt;/evaluation_dimension>        &lt;creation_requirements>&amp;#123;self.creation_requirements&amp;#125;&lt;/creation_requirements>        &lt;content>&amp;#123;self.content&amp;#125;&lt;/content>"""</span><span class="token comment" spellcheck="true"># 读取CSV文件并存储到列表中</span><span class="token keyword">def</span> <span class="token function">read_csv_to_data_objects</span><span class="token punctuation">(</span>file_path<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true"># 读取CSV文件，跳过第一行</span>    df <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span>file_path<span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">"utf-8"</span><span class="token punctuation">,</span>skiprows<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> header<span class="token operator">=</span>None<span class="token punctuation">,</span> names<span class="token operator">=</span><span class="token punctuation">[</span>                     <span class="token string">'data_id'</span><span class="token punctuation">,</span> <span class="token string">'creation_requirements'</span><span class="token punctuation">,</span> <span class="token string">'content'</span><span class="token punctuation">,</span> <span class="token string">'evaluation_dimension'</span><span class="token punctuation">,</span> <span class="token string">'score'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 创建DataObject实例的列表</span>    data_objects <span class="token operator">=</span> <span class="token punctuation">[</span>        DataObject<span class="token punctuation">(</span>row<span class="token punctuation">[</span><span class="token string">'data_id'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> row<span class="token punctuation">[</span><span class="token string">'creation_requirements'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> row<span class="token punctuation">[</span><span class="token string">'content'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                   row<span class="token punctuation">[</span><span class="token string">'evaluation_dimension'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> row<span class="token punctuation">[</span><span class="token string">'score'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        <span class="token keyword">for</span> _<span class="token punctuation">,</span> row <span class="token keyword">in</span> df<span class="token punctuation">.</span>iterrows<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token punctuation">]</span>    <span class="token keyword">return</span> data_objects<span class="token comment" spellcheck="true"># 示例用法</span>file_path <span class="token operator">=</span> <span class="token string">'train_e.csv'</span>data_objects <span class="token operator">=</span> read_csv_to_data_objects<span class="token punctuation">(</span>file_path<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">"len = &amp;#123;len(data_objects)&amp;#125;"</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 打印每个对象的字符串表示</span><span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">2</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">print</span><span class="token punctuation">(</span>data_objects<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">.</span>to_string<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span></code></pre><pre><code>len = 3500        &lt;evaluation_dimension&gt;美国塔科马市（47°17&#39;N，122°28&#39;W，是北太平洋东岸的港口城市，位于，人口约21.9万（2020年）。该市一位名叫约克的年轻人，非常喜爱中国文化的，工作之余经常前往图书馆读书，或漫步公园游憩。1873年，横贯美洲大陆的北太平洋铁路建成。这条铁路成了分处铁路两端的约克曾祖父母缔结姻缘的纽带。他们初识时，塔科马位于铁路西端，千余人仅居住于此，到1889年人口达3.6万。图12示意塔科马市内部空间结构。&lt;/evaluation_dimension&gt;        &lt;creation_requirements&gt;nan&lt;/creation_requirements&gt;        &lt;content&gt;流畅性&lt;/content&gt;</code></pre><p>​<br>​<br>​            <evaluation_dimension>中国人民银行上海总部，各省、自治区、直辖市及计划单列市分行；各政策性银行、国有商业银行，中国邮政储蓄银行，各股份制商业银行：<br>​    中国人民银行位于上海的总部机构，以及遍布全国各省、自治区、直辖市以及计划单列市的分行；同时，各政策性银行、所有国有商业银行、中国邮政储蓄银行，以及各股份制商业银行均被告知：</evaluation_dimension><br>​            <creation_requirements>请以“针对中国人民银行及其各级分支机构，以及各类银行机构（包括政策性银行、国有商业银行、中国邮政储蓄银行和股份制商业银行）发布的一项通知或指示，但由于文章正文部分未给出，具体通知或指示的内容无法确定。因此，总结为：该文章是对上述金融机构发出的一个正式通知或指示，但具体内容和目的需要查看文章的详细内容才能得知。中国人民银行决定自2024年5月18日起下调个人住房公积金贷款利率，其中首套和二套房的贷款利率均有所降低。”为主题写一篇文章</creation_requirements><br>​            <content>规范性</content></p><p>​<br>​    </p><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 构造思维链</span>cot_prompt <span class="token operator">=</span> f<span class="token triple-quoted-string string">"""请根据以下步骤对user提供的文本进行评分。请按照每一步提供的指导进行操作。1. 识别题型：    - 阅读 &lt;evaluation_dimension>&lt;/evaluation_dimension> 标签中的内容。    - 判断该内容是“选择题”还是“非选择题”。2. 如果是选择题：    - 检查 &lt;content>&lt;/content> 中的答案是否正确。    - 如果答案正确，输出 score=1。    - 如果答案错误，输出 score=0。3. 如果是非选择题：    - 阅读 &lt;evaluation_dimension>&lt;/evaluation_dimension> 标签中的内容。    - 判断该维度是流畅性还是规范性。4. 如果维度是流畅性：    - 先阅读 &lt;creation_requirements>&lt;/creation_requirements>，再阅读 &lt;content>&lt;/content>。    - 根据不同的评分标准，具体步骤如下：    - 根据以下标准对文章的语句通顺性、语法错误、字词错误、表述方式进行评分：        - 1分：非常不流畅，不具备可读性。语法错误明显，难以理解；大量拼写错误和错别字，影响阅读；表达不清晰，难以捉摸要表达的意思。(2.5,∞]个错误/百字。        - 2分：具有可读性，但较不流畅。常见语法错误多，需花费一定时间理解；一些拼写错误和错别字，阅读中断；表达较为模糊，需用一些猜测才能明白含义。(2,2.5]个错误/百字。        - 3分：基本流畅，存在少量语法错误，但影响较小。稍有拼写错误，但不影响阅读；主要意思表达清楚，但部分地方表述不够准确。(1,2]个错误/百字。        - 4分：较流畅，语法错误稀少，易读性较高。几乎无拼写错误，阅读顺畅；表达清晰、准确，容易理解。(0.5,1]个错误/百字。        - 5分：非常流畅，语法、拼写完美，阅读体验优秀。表达精炼、准确、得体；文句优美，行文连贯，思维严密。[0,0.5]个错误/百字。5. 如果维度是规范性：    - 先阅读 &lt;creation_requirements>&lt;/creation_requirements>，再阅读 &lt;content>&lt;/content>。    - 根据以下标准对文章的内容遵循性、格式规范性、语句逻辑、层次结构进行评分：        - 1分：创作内容离题，与提示语句要求不符，格式非常不规范。杂乱无章，句子结构混乱，缺乏逻辑。(5,∞]个错误/千字。        - 2分：创作内容与提示语句要求有一定契合但覆盖不全，格式较不规范。缺乏清晰的结构，但基本逻辑仍能找到。(4,5]个错误/千字。        - 3分：创作内容与提示语句要求基本契合但覆盖不全，格式一般规范。结构基本顺畅，逻辑较清晰。(2,4]个错误/千字。        - 4分：创作内容与提示语句要求基本契合且基本覆盖，格式较规范。结构清晰，逻辑条理分明。(1,2]个错误/千字。        - 5分：创作内容与提示语句要求完美契合，格式非常规范。结构严谨，逻辑清晰，层次分明。[0,1]个错误/千字。6. 最终输出：    - 根据以上分析，给出最终的评分，并以“score=分数”的形式输出。"""</span><span class="token keyword">import</span> re</code></pre><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd<span class="token keyword">class</span> <span class="token class-name">DataObject</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> data_id<span class="token punctuation">,</span> creation_requirements<span class="token punctuation">,</span> content<span class="token punctuation">,</span> evaluation_dimension<span class="token punctuation">,</span> score<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>data_id <span class="token operator">=</span> data_id  <span class="token comment" spellcheck="true"># 数据编号</span>        self<span class="token punctuation">.</span>creation_requirements <span class="token operator">=</span> creation_requirements  <span class="token comment" spellcheck="true"># 创作要求（仅规范性数据包含）/选择题题目</span>        self<span class="token punctuation">.</span>content <span class="token operator">=</span> content  <span class="token comment" spellcheck="true"># 待评判内容/选择题答案及模型回复</span>        self<span class="token punctuation">.</span>evaluation_dimension <span class="token operator">=</span> evaluation_dimension  <span class="token comment" spellcheck="true"># 评判维度</span>        self<span class="token punctuation">.</span>score <span class="token operator">=</span> score  <span class="token comment" spellcheck="true"># 分值</span>    <span class="token keyword">def</span> <span class="token function">to_string</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> f<span class="token triple-quoted-string string">"""        &lt;evaluation_dimension>&amp;#123;self.evaluation_dimension&amp;#125;&lt;/evaluation_dimension>        &lt;creation_requirements>&amp;#123;self.creation_requirements&amp;#125;&lt;/creation_requirements>        &lt;content>&amp;#123;self.content&amp;#125;&lt;/content>"""</span><span class="token comment" spellcheck="true"># 读取CSV文件并存储到列表中</span><span class="token keyword">def</span> <span class="token function">read_csv_to_data_objects</span><span class="token punctuation">(</span>file_path<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true"># 读取CSV文件，跳过第一行</span>    df <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span>file_path<span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">"utf-8"</span><span class="token punctuation">,</span>skiprows<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">,</span> header<span class="token operator">=</span>None<span class="token punctuation">,</span> names<span class="token operator">=</span><span class="token punctuation">[</span>                     <span class="token string">'data_id'</span><span class="token punctuation">,</span> <span class="token string">'creation_requirements'</span><span class="token punctuation">,</span> <span class="token string">'evaluation_dimension'</span><span class="token punctuation">,</span> <span class="token string">'content'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 创建DataObject实例的列表</span>    data_objects <span class="token operator">=</span> <span class="token punctuation">[</span>        DataObject<span class="token punctuation">(</span>row<span class="token punctuation">[</span><span class="token string">'data_id'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> row<span class="token punctuation">[</span><span class="token string">'creation_requirements'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> row<span class="token punctuation">[</span><span class="token string">'content'</span><span class="token punctuation">]</span><span class="token punctuation">,</span>                   row<span class="token punctuation">[</span><span class="token string">'evaluation_dimension'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        <span class="token keyword">for</span> _<span class="token punctuation">,</span> row <span class="token keyword">in</span> df<span class="token punctuation">.</span>iterrows<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token punctuation">]</span>    <span class="token keyword">return</span> data_objects<span class="token comment" spellcheck="true"># 示例用法</span>file_path <span class="token operator">=</span> <span class="token string">'test_e.csv'</span>data_objects <span class="token operator">=</span> read_csv_to_data_objects<span class="token punctuation">(</span>file_path<span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>data_objects<span class="token punctuation">[</span><span class="token number">333</span><span class="token punctuation">]</span><span class="token punctuation">.</span>evaluation_dimension<span class="token punctuation">)</span></code></pre><pre><code>规范性</code></pre><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> time<span class="token keyword">import</span> asyncio<span class="token keyword">import</span> json<span class="token keyword">import</span> os<span class="token keyword">import</span> nest_asyncio<span class="token keyword">from</span> tqdm<span class="token punctuation">.</span>asyncio <span class="token keyword">import</span> tqdm_asyncio<span class="token keyword">from</span> openai <span class="token keyword">import</span> AsyncOpenAI<span class="token keyword">import</span> re<span class="token keyword">import</span> csv<span class="token comment" spellcheck="true"># 允许在已有事件循环中嵌套调用异步代码</span>nest_asyncio<span class="token punctuation">.</span>apply<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">async</span> <span class="token keyword">def</span> <span class="token function">fetch_completion</span><span class="token punctuation">(</span>client<span class="token punctuation">,</span> data_object<span class="token punctuation">,</span> model_name<span class="token punctuation">,</span> n<span class="token punctuation">)</span><span class="token punctuation">:</span>    messages <span class="token operator">=</span> <span class="token punctuation">[</span>        <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;"role": "system", "content": cot_prompt&amp;#125;,</span>        <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;"role": "user", "content": data_object.to_string()&amp;#125;</span>    <span class="token punctuation">]</span>    start_time <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>    completion <span class="token operator">=</span> <span class="token keyword">await</span> client<span class="token punctuation">.</span>chat<span class="token punctuation">.</span>completions<span class="token punctuation">.</span>create<span class="token punctuation">(</span>        model<span class="token operator">=</span>model_name<span class="token punctuation">,</span>        messages<span class="token operator">=</span>messages    <span class="token punctuation">)</span>    elapsed_time <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> start_time    response <span class="token operator">=</span> completion<span class="token punctuation">.</span>choices<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>message<span class="token punctuation">.</span>content    <span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">"第 &amp;#123;n+1&amp;#125; 条数据用时: &amp;#123;elapsed_time:.2f&amp;#125; 秒"</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># print(f"第 &amp;#123;n+1&amp;#125; 条数据输出为: &amp;#123;response&amp;#125;")</span>    <span class="token comment" spellcheck="true"># 使用正则表达式匹配score后的值</span>    pattern <span class="token operator">=</span> r<span class="token string">"score=([0-9])"</span>    <span class="token comment" spellcheck="true"># 搜索匹配项</span>    match <span class="token operator">=</span> re<span class="token punctuation">.</span>search<span class="token punctuation">(</span>pattern<span class="token punctuation">,</span> response<span class="token punctuation">)</span>    <span class="token keyword">if</span> match<span class="token punctuation">:</span>        score <span class="token operator">=</span> int<span class="token punctuation">(</span>match<span class="token punctuation">.</span>group<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">else</span><span class="token punctuation">:</span>        score <span class="token operator">=</span> <span class="token number">0</span>        <span class="token keyword">return</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;</span>        <span class="token string">"data_id"</span><span class="token punctuation">:</span> data_object<span class="token punctuation">.</span>data_id<span class="token punctuation">,</span>        <span class="token string">"evaluation_dimension"</span><span class="token punctuation">:</span>data_object<span class="token punctuation">.</span>evaluation_dimension<span class="token punctuation">,</span>        <span class="token string">"score"</span><span class="token punctuation">:</span>score    <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#125;</span><span class="token comment" spellcheck="true"># async def baseline_model(client, data_objects, model_name):</span><span class="token comment" spellcheck="true">#     res = []</span><span class="token comment" spellcheck="true">#     data_objects_list = [fetch_completion(client, data_objects[i], model_name, i) for i in range(len(data_objects))]</span><span class="token comment" spellcheck="true">#     for result in tqdm_asyncio.as_completed(data_objects_list, desc='Processing data_objects'):</span><span class="token comment" spellcheck="true">#         result_data = await result</span><span class="token comment" spellcheck="true">#         # print(f'Processing data_object: &amp;#123;result_data["data_id"]&amp;#125;')</span><span class="token comment" spellcheck="true">#         res.append(result_data)</span><span class="token comment" spellcheck="true">#     return res</span><span class="token keyword">async</span> <span class="token keyword">def</span> <span class="token function">baseline_model</span><span class="token punctuation">(</span>client<span class="token punctuation">,</span> data_objects<span class="token punctuation">,</span> model_name<span class="token punctuation">)</span><span class="token punctuation">:</span>    res <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    batch_size <span class="token operator">=</span> max<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span> len<span class="token punctuation">(</span>data_objects<span class="token punctuation">)</span> <span class="token operator">//</span> <span class="token number">15</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># Calculate batch size as 1/10 of data_objects</span>    <span class="token keyword">for</span> i <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> len<span class="token punctuation">(</span>data_objects<span class="token punctuation">)</span><span class="token punctuation">,</span> batch_size<span class="token punctuation">)</span><span class="token punctuation">:</span>        batch <span class="token operator">=</span> data_objects<span class="token punctuation">[</span>i<span class="token punctuation">:</span>i <span class="token operator">+</span> batch_size<span class="token punctuation">]</span>        tasks <span class="token operator">=</span> <span class="token punctuation">[</span>fetch_completion<span class="token punctuation">(</span>client<span class="token punctuation">,</span> obj<span class="token punctuation">,</span> model_name<span class="token punctuation">,</span> i <span class="token operator">+</span> j<span class="token punctuation">)</span> <span class="token keyword">for</span> j<span class="token punctuation">,</span> obj <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>batch<span class="token punctuation">)</span><span class="token punctuation">]</span>        <span class="token keyword">for</span> result <span class="token keyword">in</span> tqdm_asyncio<span class="token punctuation">.</span>as_completed<span class="token punctuation">(</span>tasks<span class="token punctuation">,</span> desc<span class="token operator">=</span><span class="token string">'Processing data_objects'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            result_data <span class="token operator">=</span> <span class="token keyword">await</span> result            res<span class="token punctuation">.</span>append<span class="token punctuation">(</span>result_data<span class="token punctuation">)</span>    <span class="token keyword">return</span> res    <span class="token keyword">def</span> <span class="token function">write_results_to_csv</span><span class="token punctuation">(</span>results<span class="token punctuation">,</span> file_path<span class="token punctuation">)</span><span class="token punctuation">:</span>    os<span class="token punctuation">.</span>makedirs<span class="token punctuation">(</span>file_path<span class="token punctuation">,</span> exist_ok<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>    submit_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>file_path<span class="token punctuation">,</span> <span class="token string">"submit.csv"</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># CSV header</span>    headers <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">"数据编号"</span><span class="token punctuation">,</span> <span class="token string">"评判维度"</span><span class="token punctuation">,</span> <span class="token string">"预测分数"</span><span class="token punctuation">]</span>        <span class="token comment" spellcheck="true"># Write results to CSV file</span>    <span class="token keyword">with</span> open<span class="token punctuation">(</span>submit_path<span class="token punctuation">,</span> <span class="token string">'w'</span><span class="token punctuation">,</span> newline<span class="token operator">=</span><span class="token string">''</span><span class="token punctuation">,</span> encoding<span class="token operator">=</span><span class="token string">'utf-8'</span><span class="token punctuation">)</span> <span class="token keyword">as</span> csvfile<span class="token punctuation">:</span>        writer <span class="token operator">=</span> csv<span class="token punctuation">.</span>writer<span class="token punctuation">(</span>csvfile<span class="token punctuation">)</span>                <span class="token comment" spellcheck="true"># Write the header</span>        writer<span class="token punctuation">.</span>writerow<span class="token punctuation">(</span>headers<span class="token punctuation">)</span>                <span class="token comment" spellcheck="true"># Write each result as a row</span>        <span class="token keyword">for</span> result <span class="token keyword">in</span> results<span class="token punctuation">:</span>            writer<span class="token punctuation">.</span>writerow<span class="token punctuation">(</span><span class="token punctuation">[</span>result<span class="token punctuation">[</span><span class="token string">"data_id"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> result<span class="token punctuation">[</span><span class="token string">"evaluation_dimension"</span><span class="token punctuation">]</span><span class="token punctuation">,</span> result<span class="token punctuation">[</span><span class="token string">"score"</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token keyword">async</span> <span class="token keyword">def</span> <span class="token function">main</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        client <span class="token operator">=</span> AsyncOpenAI<span class="token punctuation">(</span>api_key<span class="token operator">=</span><span class="token string">'sk-wjkljhfdhajfhkadfkh'</span><span class="token punctuation">,</span>                         base_url<span class="token operator">=</span><span class="token string">'http://0.0.0.0:23333/v1'</span><span class="token punctuation">)</span>    model_cards <span class="token operator">=</span> <span class="token keyword">await</span> client<span class="token punctuation">.</span>models<span class="token punctuation">.</span>list<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>_get_page<span class="token punctuation">(</span><span class="token punctuation">)</span>    model_name <span class="token operator">=</span> model_cards<span class="token punctuation">.</span>data<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>id    res <span class="token operator">=</span> <span class="token keyword">await</span> baseline_model<span class="token punctuation">(</span>client<span class="token punctuation">,</span> data_objects<span class="token punctuation">,</span> model_name<span class="token punctuation">)</span>    <span class="token keyword">return</span> res</code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 运行异步主函数</span><span class="token comment" spellcheck="true"># 使用示例</span><span class="token comment" spellcheck="true"># results = await baseline_model(client, data_objects, model_name)</span><span class="token comment" spellcheck="true"># write_results_to_csv(results, "path/to/save/")</span>all_start_time <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>res <span class="token operator">=</span> asyncio<span class="token punctuation">.</span>run<span class="token punctuation">(</span>main<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span>all_time <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> all_start_timewrite_results_to_csv<span class="token punctuation">(</span>res<span class="token punctuation">,</span> <span class="token string">"./"</span><span class="token punctuation">)</span><span class="token keyword">print</span><span class="token punctuation">(</span>all_time<span class="token punctuation">)</span></code></pre><p>Processing data_objects:  29%|██▉       | 59&#x2F;203 [00:54&lt;00:55,  2.59it&#x2F;s]<br>第 435 条数据用时: 53.82 秒<br>Processing data_objects:  30%|██▉       | 60&#x2F;203 [00:54&lt;00:49,  2.90it&#x2F;s]<br>第 608 条数据用时: 54.19 秒</p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
          <category> 比赛 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> LLM </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>音频三分类任务</title>
      <link href="/post/1.html"/>
      <url>/post/1.html</url>
      
        <content type="html"><![CDATA[<p>%%  %%<br>仓库：<a href="https://github.com/Volta-lemon/SchoolStudy">GitHub - Volta-lemon&#x2F;SchoolStudy: 学业需要</a></p><h1 id="1-数据处理"><a href="#1-数据处理" class="headerlink" title="1. 数据处理"></a>1. 数据处理</h1><h2 id="1-1-提取原始csv到txt"><a href="#1-1-提取原始csv到txt" class="headerlink" title="1.1 提取原始csv到txt"></a>1.1 提取原始csv到txt</h2><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pddf <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'neurips_2021_zenodo_0_0_1.csv'</span><span class="token punctuation">)</span>df<span class="token punctuation">[</span><span class="token string">'sound_type'</span><span class="token punctuation">]</span> <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token string">'sound_type'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>map<span class="token punctuation">(</span><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;'mosquito': 0, 'audio': 1, 'background': 2&amp;#125;)</span>df <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token string">'id'</span><span class="token punctuation">,</span> <span class="token string">'sound_type'</span><span class="token punctuation">]</span><span class="token punctuation">]</span>df<span class="token punctuation">.</span>to_csv<span class="token punctuation">(</span><span class="token string">'wenzi.txt'</span><span class="token punctuation">,</span> header<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> index<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> sep<span class="token operator">=</span><span class="token string">','</span><span class="token punctuation">)</span></code></pre><p>安装必要的库</p><pre class=" language-python"><code class="language-python"><span class="token operator">%</span>pip install pandas opencv<span class="token operator">-</span>python moviepy librosa matplotlib numpy timm <span class="token operator">-</span>i https<span class="token punctuation">:</span><span class="token operator">//</span>pypi<span class="token punctuation">.</span>tuna<span class="token punctuation">.</span>tsinghua<span class="token punctuation">.</span>edu<span class="token punctuation">.</span>cn<span class="token operator">//</span>simple </code></pre><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> torchtorch<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>torch<span class="token punctuation">.</span>backends<span class="token punctuation">.</span>cudnn<span class="token punctuation">.</span>deterministic <span class="token operator">=</span> <span class="token boolean">False</span>torch<span class="token punctuation">.</span>backends<span class="token punctuation">.</span>cudnn<span class="token punctuation">.</span>benchmark <span class="token operator">=</span> <span class="token boolean">True</span><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">import</span> torchvision<span class="token punctuation">.</span>models <span class="token keyword">as</span> models<span class="token keyword">import</span> torchvision<span class="token punctuation">.</span>transforms <span class="token keyword">as</span> transforms<span class="token keyword">import</span> torchvision<span class="token punctuation">.</span>datasets <span class="token keyword">as</span> datasets<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F<span class="token keyword">import</span> torch<span class="token punctuation">.</span>optim <span class="token keyword">as</span> optim<span class="token keyword">from</span> torch<span class="token punctuation">.</span>autograd <span class="token keyword">import</span> Variable<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>dataset <span class="token keyword">import</span> Dataset<span class="token keyword">import</span> timm<span class="token keyword">import</span> time<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">import</span> glob<span class="token punctuation">,</span> os<span class="token keyword">from</span> PIL <span class="token keyword">import</span> Image</code></pre><h2 id="1-2-将音频数据转为mel"><a href="#1-2-将音频数据转为mel" class="headerlink" title="1.2 将音频数据转为mel"></a>1.2 将音频数据转为mel</h2><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> moviepy<span class="token punctuation">.</span>editor <span class="token keyword">as</span> mp<span class="token keyword">import</span> librosa<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">import</span> cv2<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt<span class="token keyword">from</span> matplotlib <span class="token keyword">import</span> cm<span class="token keyword">def</span> <span class="token function">generate_mel_spectrogram</span><span class="token punctuation">(</span>audio_path<span class="token punctuation">,</span> n_mels<span class="token operator">=</span><span class="token number">128</span><span class="token punctuation">,</span> fmax<span class="token operator">=</span><span class="token number">8000</span><span class="token punctuation">,</span> target_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true"># 加载音频文件</span>    y<span class="token punctuation">,</span> sr <span class="token operator">=</span> librosa<span class="token punctuation">.</span>load<span class="token punctuation">(</span>audio_path<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 生成MEL频谱图</span>    S <span class="token operator">=</span> librosa<span class="token punctuation">.</span>feature<span class="token punctuation">.</span>melspectrogram<span class="token punctuation">(</span>y<span class="token operator">=</span>y<span class="token punctuation">,</span> sr<span class="token operator">=</span>sr<span class="token punctuation">,</span> n_mels<span class="token operator">=</span>n_mels<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 将频谱图转换为dB单位</span>    S_dB <span class="token operator">=</span> librosa<span class="token punctuation">.</span>power_to_db<span class="token punctuation">(</span>S<span class="token punctuation">,</span> ref<span class="token operator">=</span>np<span class="token punctuation">.</span>max<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 归一化到0-255之间</span>    S_dB_normalized <span class="token operator">=</span> cv2<span class="token punctuation">.</span>normalize<span class="token punctuation">(</span>S_dB<span class="token punctuation">,</span> None<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">255</span><span class="token punctuation">,</span> cv2<span class="token punctuation">.</span>NORM_MINMAX<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 将浮点数转换为无符号8位整型</span>    S_dB_normalized <span class="token operator">=</span> S_dB_normalized<span class="token punctuation">.</span>astype<span class="token punctuation">(</span>np<span class="token punctuation">.</span>uint8<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 缩放到目标大小</span>    img_resized <span class="token operator">=</span> cv2<span class="token punctuation">.</span>resize<span class="token punctuation">(</span>S_dB_normalized<span class="token punctuation">,</span> target_size<span class="token punctuation">,</span> interpolation<span class="token operator">=</span>cv2<span class="token punctuation">.</span>INTER_LINEAR<span class="token punctuation">)</span>    <span class="token keyword">return</span> img_resized<span class="token comment" spellcheck="true"># 使用示例</span>audio_path <span class="token operator">=</span> <span class="token string">'.\\data\\audio\\222687.wav'</span>  <span class="token comment" spellcheck="true"># 替换为您的视频文件路径</span>mel_spectrogram_image <span class="token operator">=</span> generate_mel_spectrogram<span class="token punctuation">(</span>audio_path<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 显示图片</span>plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 可以调整图像大小</span>plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>mel_spectrogram_image<span class="token punctuation">,</span> aspect<span class="token operator">=</span><span class="token string">'auto'</span><span class="token punctuation">,</span> origin<span class="token operator">=</span><span class="token string">'lower'</span><span class="token punctuation">,</span> cmap<span class="token operator">=</span><span class="token string">'viridis'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>colorbar<span class="token punctuation">(</span>format<span class="token operator">=</span><span class="token string">'%+2.0f dB'</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 显示颜色条</span>plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'MEL Spectrogram'</span><span class="token punctuation">)</span>plt<span class="token punctuation">.</span>tight_layout<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 确保布局整齐</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><p>​<br><img src="https://volta-1309445959.cos.ap-beijing.myqcloud.com/blog/med_7_0.png" alt="png"><br>​    </p><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> os<span class="token keyword">import</span> librosa<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">import</span> cv2<span class="token keyword">from</span> tqdm <span class="token keyword">import</span> tqdm<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt<span class="token keyword">from</span> matplotlib <span class="token keyword">import</span> cm<span class="token keyword">def</span> <span class="token function">generate_mel_spectrogram</span><span class="token punctuation">(</span>audio_path<span class="token punctuation">,</span> save_path<span class="token punctuation">,</span> n_mels<span class="token operator">=</span><span class="token number">128</span><span class="token punctuation">,</span> fmax<span class="token operator">=</span><span class="token number">8000</span><span class="token punctuation">,</span> target_size<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true"># 加载音频文件</span>    y<span class="token punctuation">,</span> sr <span class="token operator">=</span> librosa<span class="token punctuation">.</span>load<span class="token punctuation">(</span>audio_path<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 生成MEL频谱图</span>    S <span class="token operator">=</span> librosa<span class="token punctuation">.</span>feature<span class="token punctuation">.</span>melspectrogram<span class="token punctuation">(</span>y<span class="token operator">=</span>y<span class="token punctuation">,</span> sr<span class="token operator">=</span>sr<span class="token punctuation">,</span> n_mels<span class="token operator">=</span>n_mels<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 将频谱图转换为dB单位</span>    S_dB <span class="token operator">=</span> librosa<span class="token punctuation">.</span>power_to_db<span class="token punctuation">(</span>S<span class="token punctuation">,</span> ref<span class="token operator">=</span>np<span class="token punctuation">.</span>max<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 归一化到0-255之间</span>    S_dB_normalized <span class="token operator">=</span> cv2<span class="token punctuation">.</span>normalize<span class="token punctuation">(</span>S_dB<span class="token punctuation">,</span> None<span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">255</span><span class="token punctuation">,</span> cv2<span class="token punctuation">.</span>NORM_MINMAX<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 将浮点数转换为无符号8位整型</span>    S_dB_normalized <span class="token operator">=</span> S_dB_normalized<span class="token punctuation">.</span>astype<span class="token punctuation">(</span>np<span class="token punctuation">.</span>uint8<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 缩放到目标大小</span>    img_resized <span class="token operator">=</span> cv2<span class="token punctuation">.</span>resize<span class="token punctuation">(</span>S_dB_normalized<span class="token punctuation">,</span> target_size<span class="token punctuation">,</span> interpolation<span class="token operator">=</span>cv2<span class="token punctuation">.</span>INTER_LINEAR<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># 保存图片</span>    cv2<span class="token punctuation">.</span>imwrite<span class="token punctuation">(</span>save_path<span class="token punctuation">,</span> img_resized<span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">process_audio_files</span><span class="token punctuation">(</span>audio_dir<span class="token punctuation">,</span> pic_dir<span class="token punctuation">)</span><span class="token punctuation">:</span>    audio_files <span class="token operator">=</span> <span class="token punctuation">[</span>f <span class="token keyword">for</span> f <span class="token keyword">in</span> os<span class="token punctuation">.</span>listdir<span class="token punctuation">(</span>audio_dir<span class="token punctuation">)</span> <span class="token keyword">if</span> f<span class="token punctuation">.</span>endswith<span class="token punctuation">(</span><span class="token string">'.wav'</span><span class="token punctuation">)</span><span class="token punctuation">]</span>    <span class="token keyword">for</span> file <span class="token keyword">in</span> tqdm<span class="token punctuation">(</span>audio_files<span class="token punctuation">,</span> desc<span class="token operator">=</span><span class="token string">"Processing Audio Files"</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">try</span><span class="token punctuation">:</span>            audio_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>audio_dir<span class="token punctuation">,</span> file<span class="token punctuation">)</span>            save_path <span class="token operator">=</span> os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>join<span class="token punctuation">(</span>pic_dir<span class="token punctuation">,</span> file<span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token string">'.wav'</span><span class="token punctuation">,</span> <span class="token string">'.jpg'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>            generate_mel_spectrogram<span class="token punctuation">(</span>audio_path<span class="token punctuation">,</span> save_path<span class="token punctuation">)</span>        <span class="token keyword">except</span> Exception <span class="token keyword">as</span> e<span class="token punctuation">:</span>            <span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">"Error processing &amp;#123;audio_path&amp;#125;: &amp;#123;e&amp;#125;"</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 目录路径设置</span>audio_dir <span class="token operator">=</span> <span class="token string">'.\\data\\audio\\'</span>pic_dir <span class="token operator">=</span> <span class="token string">'.\\data\\pic\\'</span>os<span class="token punctuation">.</span>makedirs<span class="token punctuation">(</span>pic_dir<span class="token punctuation">,</span> exist_ok<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 确保输出目录存在</span><span class="token comment" spellcheck="true"># 处理所有音频文件</span>process_audio_files<span class="token punctuation">(</span>audio_dir<span class="token punctuation">,</span> pic_dir<span class="token punctuation">)</span></code></pre><pre><code>Processing Audio Files: 100%|██████████| 9295/9295 [07:37&lt;00:00, 20.32it/s]</code></pre><pre class=" language-python"><code class="language-python"><span class="token keyword">def</span> <span class="token function">display_mel_spectrogram</span><span class="token punctuation">(</span>image_path<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true"># 使用OpenCV读取图片</span>    img <span class="token operator">=</span> cv2<span class="token punctuation">.</span>imread<span class="token punctuation">(</span>image_path<span class="token punctuation">,</span> cv2<span class="token punctuation">.</span>IMREAD_GRAYSCALE<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 使用matplotlib显示图片</span>    plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 设置显示图像的大小</span>    plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>img<span class="token punctuation">,</span> aspect<span class="token operator">=</span><span class="token string">'auto'</span><span class="token punctuation">,</span> cmap<span class="token operator">=</span><span class="token string">'viridis'</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 使用viridis颜色映射</span>    plt<span class="token punctuation">.</span>colorbar<span class="token punctuation">(</span>format<span class="token operator">=</span><span class="token string">'%+2.0f dB'</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 显示颜色条</span>    plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'MEL Spectrogram'</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 设置图像标题</span>    plt<span class="token punctuation">.</span>tight_layout<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 确保布局整齐</span>    plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 显示图像</span><span class="token comment" spellcheck="true"># 图片目录</span>image_path <span class="token operator">=</span> <span class="token string">'.\\data\\pic\\668.jpg'</span>display_mel_spectrogram<span class="token punctuation">(</span>image_path<span class="token punctuation">)</span></code></pre><p>​<br><img src="https://volta-1309445959.cos.ap-beijing.myqcloud.com/blog/med_9_0.png" alt="png"><br>​    </p><h1 id="2-训练模型"><a href="#2-训练模型" class="headerlink" title="2. 训练模型"></a>2. 训练模型</h1><h2 id="2-1-模型选择"><a href="#2-1-模型选择" class="headerlink" title="2.1 模型选择"></a>2.1 模型选择</h2><p>主要选取了ResNet18、EfficientNet-B0、DenseNet-121，目的使用更小的参数量得到更优异的表现。</p><p>以下是 ResNet18、EfficientNet-B0、DenseNet-121、ResNet50 和 VGGish 的参数数量对比表格：</p><table><thead><tr><th>神经网络</th><th>主要结构特点</th><th>参数数量 (百万)</th></tr></thead><tbody><tr><td><strong>ResNet18</strong></td><td>残差块（Residual Block）</td><td>11.7</td></tr><tr><td><strong>EfficientNet-B0</strong></td><td>MBConv，复合缩放（Compound Scaling）</td><td>5.3</td></tr><tr><td><strong>DenseNet-121</strong></td><td>密集连接（Dense Connectivity）</td><td>8</td></tr><tr><td><strong>ResNet50</strong></td><td>残差块（Residual Block），更深层次网络</td><td>25.6</td></tr><tr><td><strong>VGGish</strong></td><td>VGG16 的变种，主要用于音频嵌入（音频分类任务）</td><td>62</td></tr></tbody></table><h3 id="ResNet18"><a href="#ResNet18" class="headerlink" title="ResNet18"></a>ResNet18</h3><p><strong>网络结构</strong>：<br>ResNet18 是 ResNet（Residual Network）系列中的一个版本，采用残差块（Residual Block）来实现网络的深层次学习。其主要结构如下：</p><ul><li><strong>输入层</strong>：7x7 卷积，64 通道，步幅 2，后接 3x3 最大池化，步幅 2</li><li><strong>残差块 1</strong>：2 个卷积层，每层 3x3，64 通道</li><li><strong>残差块 2</strong>：2 个卷积层，每层 3x3，128 通道</li><li><strong>残差块 3</strong>：2 个卷积层，每层 3x3，256 通道</li><li><strong>残差块 4</strong>：2 个卷积层，每层 3x3，512 通道</li><li><strong>全局平均池化</strong>：平均池化到 1x1</li><li><strong>全连接层</strong>：1000 单元，softmax 激活（用于 ImageNet 分类）</li></ul><h3 id="EfficientNet-B0"><a href="#EfficientNet-B0" class="headerlink" title="EfficientNet-B0"></a>EfficientNet-B0</h3><p><strong>网络结构</strong>：<br>EfficientNet-B0 是 EfficientNet 系列中的一个基础版本，以复合缩放（Compound Scaling）方法来平衡网络深度、宽度和分辨率。其主要结构如下：</p><ul><li><strong>Stem</strong>：3x3 卷积，32 通道，步幅 2</li><li><strong>MBConv1</strong>：1 个 Mobile Inverted Bottleneck，16 通道</li><li><strong>MBConv6</strong>：2 个 Mobile Inverted Bottleneck，24 通道</li><li><strong>MBConv6</strong>：2 个 Mobile Inverted Bottleneck，40 通道</li><li><strong>MBConv6</strong>：3 个 Mobile Inverted Bottleneck，80 通道</li><li><strong>MBConv6</strong>：3 个 Mobile Inverted Bottleneck，112 通道</li><li><strong>MBConv6</strong>：4 个 Mobile Inverted Bottleneck，192 通道</li><li><strong>MBConv6</strong>：1 个 Mobile Inverted Bottleneck，320 通道</li><li><strong>Head</strong>：1x1 卷积，1280 通道</li><li><strong>全局平均池化</strong>：平均池化到 1x1</li><li><strong>全连接层</strong>：1000 单元，softmax 激活（用于 ImageNet 分类）</li></ul><h3 id="DenseNet-121"><a href="#DenseNet-121" class="headerlink" title="DenseNet-121"></a>DenseNet-121</h3><p><strong>网络结构</strong>：<br>DenseNet-121 是 DenseNet（Densely Connected Convolutional Network）系列中的一个版本，通过密集连接（Dense Connectivity）来提高信息流通和梯度传递。其主要结构如下：</p><ul><li><strong>输入层</strong>：7x7 卷积，64 通道，步幅 2，后接 3x3 最大池化，步幅 2</li><li><strong>Dense Block 1</strong>：6 个 dense 层，每层 32 通道</li><li><strong>Transition Layer 1</strong>：1x1 卷积，128 通道，2x2 平均池化，步幅 2</li><li><strong>Dense Block 2</strong>：12 个 dense 层，每层 32 通道</li><li><strong>Transition Layer 2</strong>：1x1 卷积，256 通道，2x2 平均池化，步幅 2</li><li><strong>Dense Block 3</strong>：24 个 dense 层，每层 32 通道</li><li><strong>Transition Layer 3</strong>：1x1 卷积，512 通道，2x2 平均池化，步幅 2</li><li><strong>Dense Block 4</strong>：16 个 dense 层，每层 32 通道</li><li><strong>全局平均池化</strong>：平均池化到 1x1</li><li><strong>全连接层</strong>：1000 单元，softmax 激活（用于 ImageNet 分类）</li></ul><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> osos<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">'HTTP_PROXY'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">'http://127.0.0.1:7890'</span>os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">'HTTPS_PROXY'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">'http://127.0.0.1:7890'</span></code></pre><h2 id="2-2-工具类"><a href="#2-2-工具类" class="headerlink" title="2.2 工具类"></a>2.2 工具类</h2><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> osos<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">'HTTP_PROXY'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">'http://127.0.0.1:7890'</span>os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">'HTTPS_PROXY'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">'http://127.0.0.1:7890'</span><span class="token keyword">import</span> torchtorch<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>torch<span class="token punctuation">.</span>backends<span class="token punctuation">.</span>cudnn<span class="token punctuation">.</span>deterministic <span class="token operator">=</span> <span class="token boolean">False</span>torch<span class="token punctuation">.</span>backends<span class="token punctuation">.</span>cudnn<span class="token punctuation">.</span>benchmark <span class="token operator">=</span> <span class="token boolean">True</span><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">import</span> torchvision<span class="token punctuation">.</span>models <span class="token keyword">as</span> models<span class="token keyword">import</span> torchvision<span class="token punctuation">.</span>transforms <span class="token keyword">as</span> transforms<span class="token keyword">import</span> torchvision<span class="token punctuation">.</span>datasets <span class="token keyword">as</span> datasets<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F<span class="token keyword">import</span> torch<span class="token punctuation">.</span>optim <span class="token keyword">as</span> optim<span class="token keyword">from</span> torch<span class="token punctuation">.</span>autograd <span class="token keyword">import</span> Variable<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>dataset <span class="token keyword">import</span> Dataset<span class="token keyword">import</span> timm<span class="token keyword">import</span> time<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">import</span> glob<span class="token punctuation">,</span> os<span class="token keyword">from</span> PIL <span class="token keyword">import</span> Image<span class="token keyword">class</span> <span class="token class-name">AverageMeter</span><span class="token punctuation">(</span>object<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token triple-quoted-string string">"""Computes and stores the average and current value"""</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> name<span class="token punctuation">,</span> fmt<span class="token operator">=</span><span class="token string">':f'</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>name <span class="token operator">=</span> name        self<span class="token punctuation">.</span>fmt <span class="token operator">=</span> fmt        self<span class="token punctuation">.</span>reset<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">reset</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>val <span class="token operator">=</span> <span class="token number">0</span>        self<span class="token punctuation">.</span>avg <span class="token operator">=</span> <span class="token number">0</span>        self<span class="token punctuation">.</span>sum <span class="token operator">=</span> <span class="token number">0</span>        self<span class="token punctuation">.</span>count <span class="token operator">=</span> <span class="token number">0</span>    <span class="token keyword">def</span> <span class="token function">update</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> val<span class="token punctuation">,</span> n<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>val <span class="token operator">=</span> val        self<span class="token punctuation">.</span>sum <span class="token operator">+=</span> val <span class="token operator">*</span> n        self<span class="token punctuation">.</span>count <span class="token operator">+=</span> n        self<span class="token punctuation">.</span>avg <span class="token operator">=</span> self<span class="token punctuation">.</span>sum <span class="token operator">/</span> self<span class="token punctuation">.</span>count    <span class="token keyword">def</span> <span class="token function">__str__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        fmtstr <span class="token operator">=</span> <span class="token string">'&amp;#123;name&amp;#125; &amp;#123;val'</span> <span class="token operator">+</span> self<span class="token punctuation">.</span>fmt <span class="token operator">+</span> <span class="token string">'&amp;#125; (&amp;#123;avg'</span> <span class="token operator">+</span> self<span class="token punctuation">.</span>fmt <span class="token operator">+</span> <span class="token string">'&amp;#125;)'</span>        <span class="token keyword">return</span> fmtstr<span class="token punctuation">.</span>format<span class="token punctuation">(</span><span class="token operator">**</span>self<span class="token punctuation">.</span>__dict__<span class="token punctuation">)</span><span class="token keyword">class</span> <span class="token class-name">ProgressMeter</span><span class="token punctuation">(</span>object<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> num_batches<span class="token punctuation">,</span> <span class="token operator">*</span>meters<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>batch_fmtstr <span class="token operator">=</span> self<span class="token punctuation">.</span>_get_batch_fmtstr<span class="token punctuation">(</span>num_batches<span class="token punctuation">)</span>        self<span class="token punctuation">.</span>meters <span class="token operator">=</span> meters        self<span class="token punctuation">.</span>prefix <span class="token operator">=</span> <span class="token string">""</span>    <span class="token keyword">def</span> <span class="token function">pr2int</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> batch<span class="token punctuation">)</span><span class="token punctuation">:</span>        entries <span class="token operator">=</span> <span class="token punctuation">[</span>self<span class="token punctuation">.</span>prefix <span class="token operator">+</span> self<span class="token punctuation">.</span>batch_fmtstr<span class="token punctuation">.</span>format<span class="token punctuation">(</span>batch<span class="token punctuation">)</span><span class="token punctuation">]</span>        entries <span class="token operator">+=</span> <span class="token punctuation">[</span>str<span class="token punctuation">(</span>meter<span class="token punctuation">)</span> <span class="token keyword">for</span> meter <span class="token keyword">in</span> self<span class="token punctuation">.</span>meters<span class="token punctuation">]</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'\t'</span><span class="token punctuation">.</span>join<span class="token punctuation">(</span>entries<span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">def</span> <span class="token function">_get_batch_fmtstr</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> num_batches<span class="token punctuation">)</span><span class="token punctuation">:</span>        num_digits <span class="token operator">=</span> len<span class="token punctuation">(</span>str<span class="token punctuation">(</span>num_batches <span class="token operator">//</span> <span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        fmt <span class="token operator">=</span> <span class="token string">'&amp;#123;:'</span> <span class="token operator">+</span> str<span class="token punctuation">(</span>num_digits<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">'d&amp;#125;'</span>        <span class="token keyword">return</span> <span class="token string">'['</span> <span class="token operator">+</span> fmt <span class="token operator">+</span> <span class="token string">'/'</span> <span class="token operator">+</span> fmt<span class="token punctuation">.</span>format<span class="token punctuation">(</span>num_batches<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">']'</span></code></pre><h2 id="2-3-训练和验证过程"><a href="#2-3-训练和验证过程" class="headerlink" title="2.3 训练和验证过程"></a>2.3 训练和验证过程</h2><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> osos<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">'HTTP_PROXY'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">'http://127.0.0.1:7890'</span>os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">'HTTPS_PROXY'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">'http://127.0.0.1:7890'</span><span class="token keyword">import</span> torchtorch<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>torch<span class="token punctuation">.</span>backends<span class="token punctuation">.</span>cudnn<span class="token punctuation">.</span>deterministic <span class="token operator">=</span> <span class="token boolean">False</span>torch<span class="token punctuation">.</span>backends<span class="token punctuation">.</span>cudnn<span class="token punctuation">.</span>benchmark <span class="token operator">=</span> <span class="token boolean">True</span><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">import</span> torchvision<span class="token punctuation">.</span>models <span class="token keyword">as</span> models<span class="token keyword">import</span> torchvision<span class="token punctuation">.</span>transforms <span class="token keyword">as</span> transforms<span class="token keyword">import</span> torchvision<span class="token punctuation">.</span>datasets <span class="token keyword">as</span> datasets<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F<span class="token keyword">import</span> torch<span class="token punctuation">.</span>optim <span class="token keyword">as</span> optim<span class="token keyword">from</span> torch<span class="token punctuation">.</span>autograd <span class="token keyword">import</span> Variable<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>dataset <span class="token keyword">import</span> Dataset<span class="token keyword">import</span> timm<span class="token keyword">import</span> time<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">import</span> glob<span class="token punctuation">,</span> os<span class="token keyword">from</span> PIL <span class="token keyword">import</span> Image<span class="token keyword">def</span> <span class="token function">validate</span><span class="token punctuation">(</span>test_loader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> criterion<span class="token punctuation">)</span><span class="token punctuation">:</span>    batch_time <span class="token operator">=</span> AverageMeter<span class="token punctuation">(</span><span class="token string">'Time'</span><span class="token punctuation">,</span> <span class="token string">':6.3f'</span><span class="token punctuation">)</span>    losses <span class="token operator">=</span> AverageMeter<span class="token punctuation">(</span><span class="token string">'Loss'</span><span class="token punctuation">,</span> <span class="token string">':.4e'</span><span class="token punctuation">)</span>    top1 <span class="token operator">=</span> AverageMeter<span class="token punctuation">(</span><span class="token string">'Acc@1'</span><span class="token punctuation">,</span> <span class="token string">':6.2f'</span><span class="token punctuation">)</span>    progress <span class="token operator">=</span> ProgressMeter<span class="token punctuation">(</span>len<span class="token punctuation">(</span>test_loader<span class="token punctuation">)</span><span class="token punctuation">,</span> batch_time<span class="token punctuation">,</span> losses<span class="token punctuation">,</span> top1<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># switch to evaluate mode</span>    model<span class="token punctuation">.</span>eval<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        end <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">for</span> i<span class="token punctuation">,</span> <span class="token punctuation">(</span>input<span class="token punctuation">,</span> target<span class="token punctuation">)</span> <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>test_loader<span class="token punctuation">)</span><span class="token punctuation">:</span>            input <span class="token operator">=</span> input<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>            target <span class="token operator">=</span> target<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>            <span class="token comment" spellcheck="true"># compute output</span>            output <span class="token operator">=</span> model<span class="token punctuation">(</span>input<span class="token punctuation">)</span>            loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>output<span class="token punctuation">,</span> target<span class="token punctuation">)</span>            <span class="token comment" spellcheck="true"># measure accuracy and record loss</span>            acc <span class="token operator">=</span> <span class="token punctuation">(</span>output<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">==</span> target<span class="token punctuation">.</span>float<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>float<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token number">100</span>            losses<span class="token punctuation">.</span>update<span class="token punctuation">(</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> input<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>            top1<span class="token punctuation">.</span>update<span class="token punctuation">(</span>acc<span class="token punctuation">,</span> input<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>            <span class="token comment" spellcheck="true"># measure elapsed time</span>            batch_time<span class="token punctuation">.</span>update<span class="token punctuation">(</span>time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> end<span class="token punctuation">)</span>            end <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># TODO: this should also be done with the ProgressMeter</span>        <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">' * Acc@1 &amp;#123;top1.avg:.3f&amp;#125;'</span>              <span class="token punctuation">.</span>format<span class="token punctuation">(</span>top1<span class="token operator">=</span>top1<span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> top1<span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>train_loader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> criterion<span class="token punctuation">,</span> optimizer<span class="token punctuation">,</span> epoch<span class="token punctuation">)</span><span class="token punctuation">:</span>    batch_time <span class="token operator">=</span> AverageMeter<span class="token punctuation">(</span><span class="token string">'Time'</span><span class="token punctuation">,</span> <span class="token string">':6.3f'</span><span class="token punctuation">)</span>    losses <span class="token operator">=</span> AverageMeter<span class="token punctuation">(</span><span class="token string">'Loss'</span><span class="token punctuation">,</span> <span class="token string">':.4e'</span><span class="token punctuation">)</span>    top1 <span class="token operator">=</span> AverageMeter<span class="token punctuation">(</span><span class="token string">'Acc@1'</span><span class="token punctuation">,</span> <span class="token string">':6.2f'</span><span class="token punctuation">)</span>    progress <span class="token operator">=</span> ProgressMeter<span class="token punctuation">(</span>len<span class="token punctuation">(</span>train_loader<span class="token punctuation">)</span><span class="token punctuation">,</span> batch_time<span class="token punctuation">,</span> losses<span class="token punctuation">,</span> top1<span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># switch to train mode</span>    model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>    end <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> i<span class="token punctuation">,</span> <span class="token punctuation">(</span>input<span class="token punctuation">,</span> target<span class="token punctuation">)</span> <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>train_loader<span class="token punctuation">)</span><span class="token punctuation">:</span>        input <span class="token operator">=</span> input<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span>non_blocking<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>        target <span class="token operator">=</span> target<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span>non_blocking<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># compute output</span>        output <span class="token operator">=</span> model<span class="token punctuation">(</span>input<span class="token punctuation">)</span>        loss <span class="token operator">=</span> criterion<span class="token punctuation">(</span>output<span class="token punctuation">,</span> target<span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># measure accuracy and record loss</span>        losses<span class="token punctuation">.</span>update<span class="token punctuation">(</span>loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> input<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        acc <span class="token operator">=</span> <span class="token punctuation">(</span>output<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span> <span class="token operator">==</span> target<span class="token punctuation">.</span>float<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>view<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>float<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token number">100</span>        top1<span class="token punctuation">.</span>update<span class="token punctuation">(</span>acc<span class="token punctuation">,</span> input<span class="token punctuation">.</span>size<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># compute gradient and do SGD step</span>        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># measure elapsed time</span>        batch_time<span class="token punctuation">.</span>update<span class="token punctuation">(</span>time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">-</span> end<span class="token punctuation">)</span>        end <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>        <span class="token keyword">if</span> i <span class="token operator">%</span> <span class="token number">100</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>            progress<span class="token punctuation">.</span>pr2int<span class="token punctuation">(</span>i<span class="token punctuation">)</span></code></pre><h2 id="2-4-构造数据加载器"><a href="#2-4-构造数据加载器" class="headerlink" title="2.4 构造数据加载器"></a>2.4 构造数据加载器</h2><p>实测：8GB显存最好batch_size设置在20-40,40GB显存可是设置在150左右。</p><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd<span class="token keyword">import</span> os<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_split<span class="token comment" spellcheck="true"># 读取wenzi.txt文件</span>df <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'wenzi.txt'</span><span class="token punctuation">,</span> header<span class="token operator">=</span>None<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 假设文件没有表头</span><span class="token comment" spellcheck="true"># 将数据分为训练集和测试集，比例为8:2</span>train_label<span class="token punctuation">,</span> test_label <span class="token operator">=</span> train_test_split<span class="token punctuation">(</span>df<span class="token punctuation">,</span> test_size<span class="token operator">=</span><span class="token number">0.2</span><span class="token punctuation">,</span> random_state<span class="token operator">=</span><span class="token number">42</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 修改文件名，添加路径，并假设文件名是第一列</span>train_label<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> train_label<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>apply<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> str<span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">'.jpg'</span><span class="token punctuation">)</span>test_label<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> test_label<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>apply<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> str<span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">'.jpg'</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 添加path属性</span>train_label<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">'.\\data\\pic\\'</span> <span class="token operator">+</span> train_label<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>test_label<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">'.\\data\\pic\\'</span> <span class="token operator">+</span> test_label<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token comment" spellcheck="true"># 重命名第一列为目标列</span>train_label <span class="token operator">=</span> train_label<span class="token punctuation">.</span>rename<span class="token punctuation">(</span>columns<span class="token operator">=</span><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;1: 'target'&amp;#125;)</span>test_label <span class="token operator">=</span> test_label<span class="token punctuation">.</span>rename<span class="token punctuation">(</span>columns<span class="token operator">=</span><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;1: 'target'&amp;#125;)</span>train_label <span class="token operator">=</span> train_label<span class="token punctuation">.</span>rename<span class="token punctuation">(</span>columns<span class="token operator">=</span><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;0: 'path'&amp;#125;)</span>test_label <span class="token operator">=</span> test_label<span class="token punctuation">.</span>rename<span class="token punctuation">(</span>columns<span class="token operator">=</span><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;0: 'path'&amp;#125;)</span><span class="token comment" spellcheck="true"># 过滤出实际存在的文件路径</span>train_label <span class="token operator">=</span> train_label<span class="token punctuation">[</span>train_label<span class="token punctuation">[</span><span class="token string">'path'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>apply<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>exists<span class="token punctuation">)</span><span class="token punctuation">]</span>test_label <span class="token operator">=</span> test_label<span class="token punctuation">[</span>test_label<span class="token punctuation">[</span><span class="token string">'path'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>apply<span class="token punctuation">(</span>os<span class="token punctuation">.</span>path<span class="token punctuation">.</span>exists<span class="token punctuation">)</span><span class="token punctuation">]</span>train_label<span class="token punctuation">,</span>test_label<span class="token comment" spellcheck="true"># img = Image.open(train_label).convert('RGB')</span><span class="token comment" spellcheck="true"># train_label['path'].values</span></code></pre><pre><code>(                       path  target 7485  .\data\pic\201906.jpg       2 8599  .\data\pic\201361.jpg       2 2906  .\data\pic\220337.jpg       0 3994  .\data\pic\222088.jpg       0 108      .\data\pic\102.jpg       0 ...                     ...     ... 5734    .\data\pic\2417.jpg       0 5191  .\data\pic\219168.jpg       0 5390  .\data\pic\219753.jpg       2 860      .\data\pic\753.jpg       1 7270  .\data\pic\201101.jpg       2  [7436 rows x 2 columns],                        path  target 7862  .\data\pic\201201.jpg       2 1112    .\data\pic\1008.jpg       1 6909  .\data\pic\207888.jpg       0 4058  .\data\pic\220027.jpg       2 3733  .\data\pic\221824.jpg       0 ...                     ...     ... 4004  .\data\pic\222118.jpg       0 4467  .\data\pic\222549.jpg       0 6851  .\data\pic\207788.jpg       0 5048  .\data\pic\219092.jpg       2 7178  .\data\pic\201719.jpg       2  [1859 rows x 2 columns])</code></pre><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt<span class="token keyword">from</span> PIL <span class="token keyword">import</span> Imageimg <span class="token operator">=</span> Image<span class="token punctuation">.</span>open<span class="token punctuation">(</span>train_label<span class="token punctuation">[</span><span class="token string">'path'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>values<span class="token punctuation">[</span><span class="token number">33</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>convert<span class="token punctuation">(</span><span class="token string">'RGB'</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 显示图像</span>plt<span class="token punctuation">.</span>imshow<span class="token punctuation">(</span>img<span class="token punctuation">)</span>plt<span class="token punctuation">.</span>axis<span class="token punctuation">(</span><span class="token string">'off'</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 关闭坐标轴</span>plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span></code></pre><p>​<br><img src="https://volta-1309445959.cos.ap-beijing.myqcloud.com/blog/med_19_0.png" alt="png"><br>​    </p><pre class=" language-python"><code class="language-python"><span class="token keyword">class</span> <span class="token class-name">FFDIDataset</span><span class="token punctuation">(</span>Dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> img_path<span class="token punctuation">,</span> img_label<span class="token punctuation">,</span> transform<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>img_path <span class="token operator">=</span> img_path        self<span class="token punctuation">.</span>img_label <span class="token operator">=</span> img_label        <span class="token keyword">if</span> transform <span class="token keyword">is</span> <span class="token operator">not</span> None<span class="token punctuation">:</span>            self<span class="token punctuation">.</span>transform <span class="token operator">=</span> transform        <span class="token keyword">else</span><span class="token punctuation">:</span>            self<span class="token punctuation">.</span>transform <span class="token operator">=</span> None        <span class="token keyword">def</span> <span class="token function">__getitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> index<span class="token punctuation">)</span><span class="token punctuation">:</span>        img <span class="token operator">=</span> Image<span class="token punctuation">.</span>open<span class="token punctuation">(</span>self<span class="token punctuation">.</span>img_path<span class="token punctuation">[</span>index<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>convert<span class="token punctuation">(</span><span class="token string">'RGB'</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># print(f"Loaded image path: &amp;#123;self.img_path[index]&amp;#125;")</span>        <span class="token keyword">if</span> self<span class="token punctuation">.</span>transform <span class="token keyword">is</span> <span class="token operator">not</span> None<span class="token punctuation">:</span>            img <span class="token operator">=</span> self<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>img<span class="token punctuation">)</span>                <span class="token keyword">return</span> img<span class="token punctuation">,</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>self<span class="token punctuation">.</span>img_label<span class="token punctuation">[</span>index<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> len<span class="token punctuation">(</span>self<span class="token punctuation">.</span>img_path<span class="token punctuation">)</span></code></pre><pre class=" language-python"><code class="language-python">train_loader <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>    FFDIDataset<span class="token punctuation">(</span>train_label<span class="token punctuation">[</span><span class="token string">'path'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>values<span class="token punctuation">,</span> train_label<span class="token punctuation">[</span><span class="token string">'target'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>values<span class="token punctuation">,</span>             transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>                        transforms<span class="token punctuation">.</span>RandomHorizontalFlip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                        transforms<span class="token punctuation">.</span>RandomVerticalFlip<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                        transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                        transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.485</span><span class="token punctuation">,</span> <span class="token number">0.456</span><span class="token punctuation">,</span> <span class="token number">0.406</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0.229</span><span class="token punctuation">,</span> <span class="token number">0.224</span><span class="token punctuation">,</span> <span class="token number">0.225</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        <span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token punctuation">)</span><span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> pin_memory<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># num_workers=12, pin_memory=True</span>test_loader <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>    FFDIDataset<span class="token punctuation">(</span>test_label<span class="token punctuation">[</span><span class="token string">'path'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>values<span class="token punctuation">,</span> test_label<span class="token punctuation">[</span><span class="token string">'target'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>values<span class="token punctuation">,</span>             transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>                        transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                        transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.485</span><span class="token punctuation">,</span> <span class="token number">0.456</span><span class="token punctuation">,</span> <span class="token number">0.406</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0.229</span><span class="token punctuation">,</span> <span class="token number">0.224</span><span class="token punctuation">,</span> <span class="token number">0.225</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        <span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token punctuation">)</span><span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> pin_memory<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># model = timm.create_model('resnet18', pretrained=True, num_classes=3)</span><span class="token comment" spellcheck="true"># Model name: ResNet</span><span class="token comment" spellcheck="true"># Number of parameters: 11178051</span><span class="token comment" spellcheck="true"># Model state: True</span>model <span class="token operator">=</span> timm<span class="token punctuation">.</span>create_model<span class="token punctuation">(</span><span class="token string">'densenet121'</span><span class="token punctuation">,</span> pretrained<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> num_classes<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span>model <span class="token operator">=</span> model<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 检查模型名称</span><span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">"Model name: &amp;#123;model.__class__.__name__&amp;#125;"</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 检查模型参数数量</span><span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">"Number of parameters: &amp;#123;sum(p.numel() for p in model.parameters() if p.requires_grad)&amp;#125;"</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 检查模型状态（训练或评估）</span><span class="token keyword">print</span><span class="token punctuation">(</span>f<span class="token string">"Model state: &amp;#123;model.training&amp;#125;"</span><span class="token punctuation">)</span></code></pre><pre><code>Model name: DenseNetNumber of parameters: 6956931Model state: True</code></pre><h2 id="2-5-开始训练"><a href="#2-5-开始训练" class="headerlink" title="2.5 开始训练"></a>2.5 开始训练</h2><pre class=" language-python"><code class="language-python">criterion <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>optimizer <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">0.003</span><span class="token punctuation">)</span>scheduler <span class="token operator">=</span> optim<span class="token punctuation">.</span>lr_scheduler<span class="token punctuation">.</span>StepLR<span class="token punctuation">(</span>optimizer<span class="token punctuation">,</span> step_size<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">,</span> gamma<span class="token operator">=</span><span class="token number">0.85</span><span class="token punctuation">)</span>best_acc <span class="token operator">=</span> <span class="token number">0.0</span><span class="token keyword">for</span> epoch <span class="token keyword">in</span> range<span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    scheduler<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Epoch: '</span><span class="token punctuation">,</span> epoch<span class="token punctuation">)</span>    train<span class="token punctuation">(</span>train_loader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> criterion<span class="token punctuation">,</span> optimizer<span class="token punctuation">,</span> epoch<span class="token punctuation">)</span>    val_acc <span class="token operator">=</span> validate<span class="token punctuation">(</span>test_loader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> criterion<span class="token punctuation">)</span>    <span class="token keyword">if</span> val_acc<span class="token punctuation">.</span>avg<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">></span> best_acc<span class="token punctuation">:</span>        best_acc <span class="token operator">=</span> round<span class="token punctuation">(</span>val_acc<span class="token punctuation">.</span>avg<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>        torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> f<span class="token string">'./mymodel/&amp;#123;model.__class__.__name__&amp;#125;_&amp;#123;best_acc&amp;#125;.pt'</span><span class="token punctuation">)</span></code></pre><pre><code>h:\exploit_python\environment\anaconda\envs\sml\lib\site-packages\torch\optim\lr_scheduler.py:131: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate  warnings.warn(&quot;Detected call of `lr_scheduler.step()` before `optimizer.step()`. &quot;Epoch:  0[  0/372]Time  6.523 ( 6.523)Loss 9.5620e-01 (9.5620e-01)Acc@1  60.00 ( 60.00)[100/372]Time  1.020 ( 0.901)Loss 2.2830e-01 (3.9650e-01)Acc@1  90.00 ( 86.44)[200/372]Time  2.312 ( 1.529)Loss 1.8065e-01 (3.2920e-01)Acc@1  90.00 ( 88.26)[300/372]Time  2.317 ( 1.782)Loss 1.4290e-01 (2.7225e-01)Acc@1  95.00 ( 90.40) * Acc@1 84.777Epoch:  1[  0/372]Time  2.011 ( 2.011)Loss 2.0166e-01 (2.0166e-01)Acc@1  85.00 ( 85.00)[100/372]Time  1.895 ( 1.862)Loss 7.7843e-02 (1.6153e-01)Acc@1 100.00 ( 94.60)[200/372]Time  1.907 ( 1.829)Loss 5.2962e-02 (1.5118e-01)Acc@1 100.00 ( 95.15)[300/372]Time  2.093 ( 1.839)Loss 6.9164e-02 (1.4535e-01)Acc@1  95.00 ( 95.40) * Acc@1 67.456Epoch:  2[  0/372]Time  1.813 ( 1.813)Loss 4.9243e-02 (4.9243e-02)Acc@1 100.00 (100.00)[100/372]Time  1.829 ( 1.823)Loss 1.0532e-01 (1.5236e-01)Acc@1  95.00 ( 95.20)[200/372]Time  1.745 ( 1.799)Loss 8.5073e-03 (1.2893e-01)Acc@1 100.00 ( 95.65)[300/372]Time  1.804 ( 1.788)Loss 1.9210e-01 (1.2278e-01)Acc@1  95.00 ( 95.93) * Acc@1 86.606Epoch:  3[  0/372]Time  2.084 ( 2.084)Loss 1.1666e-01 (1.1666e-01)Acc@1  95.00 ( 95.00)</code></pre><h1 id="3-推理"><a href="#3-推理" class="headerlink" title="3. 推理"></a>3. 推理</h1><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> osos<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">'HTTP_PROXY'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">'http://127.0.0.1:7890'</span>os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">'HTTPS_PROXY'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">'http://127.0.0.1:7890'</span></code></pre><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> osos<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">'HTTP_PROXY'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">'http://127.0.0.1:7890'</span>os<span class="token punctuation">.</span>environ<span class="token punctuation">[</span><span class="token string">'HTTPS_PROXY'</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">'http://127.0.0.1:7890'</span><span class="token keyword">import</span> torchtorch<span class="token punctuation">.</span>manual_seed<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">)</span>torch<span class="token punctuation">.</span>backends<span class="token punctuation">.</span>cudnn<span class="token punctuation">.</span>deterministic <span class="token operator">=</span> <span class="token boolean">False</span>torch<span class="token punctuation">.</span>backends<span class="token punctuation">.</span>cudnn<span class="token punctuation">.</span>benchmark <span class="token operator">=</span> <span class="token boolean">True</span><span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">import</span> torchvision<span class="token punctuation">.</span>models <span class="token keyword">as</span> models<span class="token keyword">import</span> torchvision<span class="token punctuation">.</span>transforms <span class="token keyword">as</span> transforms<span class="token keyword">import</span> torchvision<span class="token punctuation">.</span>datasets <span class="token keyword">as</span> datasets<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn <span class="token keyword">as</span> nn<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F<span class="token keyword">import</span> torch<span class="token punctuation">.</span>optim <span class="token keyword">as</span> optim<span class="token keyword">from</span> torch<span class="token punctuation">.</span>autograd <span class="token keyword">import</span> Variable<span class="token keyword">from</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>dataset <span class="token keyword">import</span> Dataset<span class="token keyword">import</span> timm<span class="token keyword">import</span> time<span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">import</span> glob<span class="token punctuation">,</span> os<span class="token keyword">from</span> PIL <span class="token keyword">import</span> Image</code></pre><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd<span class="token keyword">import</span> os<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_split<span class="token comment" spellcheck="true"># 读取wenzi.txt文件</span>df <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'wenzi.txt'</span><span class="token punctuation">,</span> header<span class="token operator">=</span>None<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 假设文件没有表头</span><span class="token comment" spellcheck="true"># 将数据分为训练集和测试集，比例为8:2</span>train_label<span class="token punctuation">,</span> test_label <span class="token operator">=</span> train_test_split<span class="token punctuation">(</span>df<span class="token punctuation">,</span> test_size<span class="token operator">=</span><span class="token number">0.2</span><span class="token punctuation">,</span> random_state<span class="token operator">=</span><span class="token number">42</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 修改文件名，添加路径，并假设文件名是第一列</span>train_label<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> train_label<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>apply<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> str<span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">'.jpg'</span><span class="token punctuation">)</span>test_label<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> test_label<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token punctuation">.</span>apply<span class="token punctuation">(</span><span class="token keyword">lambda</span> x<span class="token punctuation">:</span> str<span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token operator">+</span> <span class="token string">'.jpg'</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 添加path属性</span>train_label<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">'.\\data\\pic\\'</span> <span class="token operator">+</span> train_label<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>test_label<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token string">'.\\data\\pic\\'</span> <span class="token operator">+</span> test_label<span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span><span class="token comment" spellcheck="true"># 重命名第一列为目标列</span>train_label <span class="token operator">=</span> train_label<span class="token punctuation">.</span>rename<span class="token punctuation">(</span>columns<span class="token operator">=</span><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;1: 'target'&amp;#125;)</span>test_label <span class="token operator">=</span> test_label<span class="token punctuation">.</span>rename<span class="token punctuation">(</span>columns<span class="token operator">=</span><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;1: 'target'&amp;#125;)</span>train_label <span class="token operator">=</span> train_label<span class="token punctuation">.</span>rename<span class="token punctuation">(</span>columns<span class="token operator">=</span><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;0: 'path'&amp;#125;)</span>test_label <span class="token operator">=</span> test_label<span class="token punctuation">.</span>rename<span class="token punctuation">(</span>columns<span class="token operator">=</span><span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;0: 'path'&amp;#125;)</span><span class="token comment" spellcheck="true"># 指定保存文件的路径</span>file_path <span class="token operator">=</span> <span class="token string">'./mymodel/wenzi_test.csv'</span><span class="token comment" spellcheck="true"># 保存 DataFrame 到 CSV 文件</span>test_label<span class="token punctuation">.</span>to_csv<span class="token punctuation">(</span>file_path<span class="token punctuation">,</span> index<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span></code></pre><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> torch<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">import</span> time<span class="token keyword">import</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>functional <span class="token keyword">as</span> F<span class="token keyword">class</span> <span class="token class-name">FFDIDataset</span><span class="token punctuation">(</span>Dataset<span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> img_path<span class="token punctuation">,</span> img_label<span class="token punctuation">,</span> transform<span class="token operator">=</span>None<span class="token punctuation">)</span><span class="token punctuation">:</span>        self<span class="token punctuation">.</span>img_path <span class="token operator">=</span> img_path        self<span class="token punctuation">.</span>img_label <span class="token operator">=</span> img_label        <span class="token keyword">if</span> transform <span class="token keyword">is</span> <span class="token operator">not</span> None<span class="token punctuation">:</span>            self<span class="token punctuation">.</span>transform <span class="token operator">=</span> transform        <span class="token keyword">else</span><span class="token punctuation">:</span>            self<span class="token punctuation">.</span>transform <span class="token operator">=</span> None        <span class="token keyword">def</span> <span class="token function">__getitem__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> index<span class="token punctuation">)</span><span class="token punctuation">:</span>        img <span class="token operator">=</span> Image<span class="token punctuation">.</span>open<span class="token punctuation">(</span>self<span class="token punctuation">.</span>img_path<span class="token punctuation">[</span>index<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>convert<span class="token punctuation">(</span><span class="token string">'RGB'</span><span class="token punctuation">)</span>        <span class="token comment" spellcheck="true"># print(f"Loaded image path: &amp;#123;self.img_path[index]&amp;#125;")</span>        <span class="token keyword">if</span> self<span class="token punctuation">.</span>transform <span class="token keyword">is</span> <span class="token operator">not</span> None<span class="token punctuation">:</span>            img <span class="token operator">=</span> self<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>img<span class="token punctuation">)</span>                <span class="token keyword">return</span> img<span class="token punctuation">,</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>np<span class="token punctuation">.</span>array<span class="token punctuation">(</span>self<span class="token punctuation">.</span>img_label<span class="token punctuation">[</span>index<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        <span class="token keyword">def</span> <span class="token function">__len__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token keyword">return</span> len<span class="token punctuation">(</span>self<span class="token punctuation">.</span>img_path<span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">predict</span><span class="token punctuation">(</span>test_loader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> tta<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">)</span><span class="token punctuation">:</span>    <span class="token comment" spellcheck="true"># switch to evaluate mode</span>    model<span class="token punctuation">.</span>eval<span class="token punctuation">(</span><span class="token punctuation">)</span>        test_pred_tta <span class="token operator">=</span> None    <span class="token keyword">for</span> _ <span class="token keyword">in</span> range<span class="token punctuation">(</span>tta<span class="token punctuation">)</span><span class="token punctuation">:</span>        test_pred <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>        <span class="token keyword">with</span> torch<span class="token punctuation">.</span>no_grad<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>            end <span class="token operator">=</span> time<span class="token punctuation">.</span>time<span class="token punctuation">(</span><span class="token punctuation">)</span>            <span class="token keyword">for</span> i<span class="token punctuation">,</span> <span class="token punctuation">(</span>input<span class="token punctuation">,</span> target<span class="token punctuation">)</span> <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>test_loader<span class="token punctuation">)</span><span class="token punctuation">:</span>                input <span class="token operator">=</span> input<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>                target <span class="token operator">=</span> target<span class="token punctuation">.</span>cuda<span class="token punctuation">(</span><span class="token punctuation">)</span>                <span class="token comment" spellcheck="true"># compute output</span>                output <span class="token operator">=</span> model<span class="token punctuation">(</span>input<span class="token punctuation">)</span>                output <span class="token operator">=</span> F<span class="token punctuation">.</span>softmax<span class="token punctuation">(</span>output<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>                output <span class="token operator">=</span> output<span class="token punctuation">.</span>data<span class="token punctuation">.</span>cpu<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span>                test_pred<span class="token punctuation">.</span>append<span class="token punctuation">(</span>output<span class="token punctuation">)</span>        test_pred <span class="token operator">=</span> np<span class="token punctuation">.</span>vstack<span class="token punctuation">(</span>test_pred<span class="token punctuation">)</span>            <span class="token keyword">if</span> test_pred_tta <span class="token keyword">is</span> None<span class="token punctuation">:</span>            test_pred_tta <span class="token operator">=</span> test_pred        <span class="token keyword">else</span><span class="token punctuation">:</span>            test_pred_tta <span class="token operator">+=</span> test_pred        <span class="token comment" spellcheck="true"># Average the predictions over TTA runs</span>    test_pred_tta <span class="token operator">/=</span> tta        <span class="token comment" spellcheck="true"># Get the class with the highest probability</span>    test_pred_classes <span class="token operator">=</span> np<span class="token punctuation">.</span>argmax<span class="token punctuation">(</span>test_pred_tta<span class="token punctuation">,</span> axis<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>        <span class="token keyword">return</span> test_pred_classes</code></pre><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 加载训练好的模型</span>model <span class="token operator">=</span> timm<span class="token punctuation">.</span>create_model<span class="token punctuation">(</span><span class="token string">'resnet18'</span><span class="token punctuation">,</span> pretrained<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> num_classes<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span>weights_path <span class="token operator">=</span> <span class="token string">'./mymodel/ResNet_99.19.pt'</span>device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">"cuda"</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">"cpu"</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 将模型移动到指定的设备</span>model<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 从本地文件加载权重</span>weights <span class="token operator">=</span> torch<span class="token punctuation">.</span>load<span class="token punctuation">(</span>weights_path<span class="token punctuation">,</span> map_location<span class="token operator">=</span>device<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 确保权重加载到相同的设备</span>model<span class="token punctuation">.</span>load_state_dict<span class="token punctuation">(</span>weights<span class="token punctuation">)</span></code></pre><pre><code>&lt;All keys matched successfully&gt;</code></pre><pre class=" language-python"><code class="language-python">test_label <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'./mymodel/test_predictions.csv'</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># 假设文件没有表头</span>test_loader <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>    FFDIDataset<span class="token punctuation">(</span>test_label<span class="token punctuation">[</span><span class="token string">'path'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>values<span class="token punctuation">,</span> test_label<span class="token punctuation">[</span><span class="token string">'target'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>values<span class="token punctuation">,</span>             transforms<span class="token punctuation">.</span>Compose<span class="token punctuation">(</span><span class="token punctuation">[</span>                        transforms<span class="token punctuation">.</span>ToTensor<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span>                        transforms<span class="token punctuation">.</span>Normalize<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.485</span><span class="token punctuation">,</span> <span class="token number">0.456</span><span class="token punctuation">,</span> <span class="token number">0.406</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0.229</span><span class="token punctuation">,</span> <span class="token number">0.224</span><span class="token punctuation">,</span> <span class="token number">0.225</span><span class="token punctuation">]</span><span class="token punctuation">)</span>        <span class="token punctuation">]</span><span class="token punctuation">)</span>    <span class="token punctuation">)</span><span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">20</span><span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">,</span> pin_memory<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>test_pred <span class="token operator">=</span> predict<span class="token punctuation">(</span>test_loader<span class="token punctuation">,</span> model<span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>test_label<span class="token punctuation">[</span><span class="token string">"resnet18_y_pred"</span><span class="token punctuation">]</span> <span class="token operator">=</span> test_predtest_label</code></pre><div><style scoped>    .dataframe tbody tr th:only-of-type {        vertical-align: middle;    }<pre><code>.dataframe tbody tr th &#123;    vertical-align: top;&#125;.dataframe thead th &#123;    text-align: right;&#125;</code></pre><p></style></p><table border="1" class="dataframe">  <thead>    <tr style="text-align: right;">      <th></th>      <th>path</th>      <th>target</th>      <th>efficientnet_b0_y_pred</th>      <th>densenet121_y_pred</th>      <th>resnet18_y_pred</th>    </tr>  </thead>  <tbody>    <tr>      <th>0</th>      <td>.\data\pic\201201.jpg</td>      <td>2</td>      <td>2</td>      <td>2</td>      <td>2</td>    </tr>    <tr>      <th>1</th>      <td>.\data\pic\1008.jpg</td>      <td>1</td>      <td>1</td>      <td>1</td>      <td>1</td>    </tr>    <tr>      <th>2</th>      <td>.\data\pic\207888.jpg</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>    </tr>    <tr>      <th>3</th>      <td>.\data\pic\220027.jpg</td>      <td>2</td>      <td>2</td>      <td>2</td>      <td>2</td>    </tr>    <tr>      <th>4</th>      <td>.\data\pic\221824.jpg</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>    </tr>    <tr>      <th>...</th>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>      <td>...</td>    </tr>    <tr>      <th>1854</th>      <td>.\data\pic\222118.jpg</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>    </tr>    <tr>      <th>1855</th>      <td>.\data\pic\222549.jpg</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>    </tr>    <tr>      <th>1856</th>      <td>.\data\pic\207788.jpg</td>      <td>0</td>      <td>0</td>      <td>0</td>      <td>0</td>    </tr>    <tr>      <th>1857</th>      <td>.\data\pic\219092.jpg</td>      <td>2</td>      <td>2</td>      <td>2</td>      <td>2</td>    </tr>    <tr>      <th>1858</th>      <td>.\data\pic\201719.jpg</td>      <td>2</td>      <td>2</td>      <td>2</td>      <td>2</td>    </tr>  </tbody></table><p>1859 rows × 5 columns</p></div><pre class=" language-python"><code class="language-python"><span class="token comment" spellcheck="true"># 指定保存文件的路径</span>file_path <span class="token operator">=</span> <span class="token string">'./mymodel/test_predictions.csv'</span><span class="token comment" spellcheck="true"># 保存 DataFrame 到 CSV 文件</span>test_label<span class="token punctuation">.</span>to_csv<span class="token punctuation">(</span>file_path<span class="token punctuation">,</span> index<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span></code></pre><h1 id="4-评估"><a href="#4-评估" class="headerlink" title="4. 评估"></a>4. 评估</h1><pre class=" language-python"><code class="language-python"><span class="token keyword">import</span> pandas <span class="token keyword">as</span> pd<span class="token keyword">import</span> numpy <span class="token keyword">as</span> np<span class="token keyword">import</span> matplotlib<span class="token punctuation">.</span>pyplot <span class="token keyword">as</span> plt<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>metrics <span class="token keyword">import</span> roc_curve<span class="token punctuation">,</span> auc<span class="token punctuation">,</span> confusion_matrix<span class="token punctuation">,</span> classification_report<span class="token punctuation">,</span> accuracy_score<span class="token punctuation">,</span> recall_score<span class="token punctuation">,</span> precision_score<span class="token punctuation">,</span> f1_score<span class="token keyword">import</span> seaborn <span class="token keyword">as</span> sns<span class="token comment" spellcheck="true"># 读取CSV文件</span>df <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">'./mymodel/test_predictions.csv'</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 提取目标变量和预测值</span>y_true <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token string">'target'</span><span class="token punctuation">]</span>y_pred_resnet <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token string">'resnet18_y_pred'</span><span class="token punctuation">]</span>y_pred_efficientnet <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token string">'efficientnet_b0_y_pred'</span><span class="token punctuation">]</span>y_pred_densenet <span class="token operator">=</span> df<span class="token punctuation">[</span><span class="token string">'densenet121_y_pred'</span><span class="token punctuation">]</span>label_mapping <span class="token operator">=</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;0: 'mosquito', 1: 'audio', 2: 'background'&amp;#125;</span>labels <span class="token operator">=</span> list<span class="token punctuation">(</span>label_mapping<span class="token punctuation">.</span>values<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 绘制ROC曲线</span><span class="token keyword">def</span> <span class="token function">plot_roc_curve</span><span class="token punctuation">(</span>y_true<span class="token punctuation">,</span> y_pred_resnet<span class="token punctuation">,</span> y_pred_efficientnet<span class="token punctuation">,</span> y_pred_densenet<span class="token punctuation">)</span><span class="token punctuation">:</span>    fpr_resnet<span class="token punctuation">,</span> tpr_resnet<span class="token punctuation">,</span> _ <span class="token operator">=</span> roc_curve<span class="token punctuation">(</span>y_true<span class="token punctuation">,</span> y_pred_resnet<span class="token punctuation">,</span> pos_label<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>    fpr_efficientnet<span class="token punctuation">,</span> tpr_efficientnet<span class="token punctuation">,</span> _ <span class="token operator">=</span> roc_curve<span class="token punctuation">(</span>y_true<span class="token punctuation">,</span> y_pred_efficientnet<span class="token punctuation">,</span> pos_label<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>    fpr_densenet<span class="token punctuation">,</span> tpr_densenet<span class="token punctuation">,</span> _ <span class="token operator">=</span> roc_curve<span class="token punctuation">(</span>y_true<span class="token punctuation">,</span> y_pred_densenet<span class="token punctuation">,</span> pos_label<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">)</span>    roc_auc_resnet <span class="token operator">=</span> auc<span class="token punctuation">(</span>fpr_resnet<span class="token punctuation">,</span> tpr_resnet<span class="token punctuation">)</span>    roc_auc_efficientnet <span class="token operator">=</span> auc<span class="token punctuation">(</span>fpr_efficientnet<span class="token punctuation">,</span> tpr_efficientnet<span class="token punctuation">)</span>    roc_auc_densenet <span class="token operator">=</span> auc<span class="token punctuation">(</span>fpr_densenet<span class="token punctuation">,</span> tpr_densenet<span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>fpr_resnet<span class="token punctuation">,</span> tpr_resnet<span class="token punctuation">,</span> color<span class="token operator">=</span><span class="token string">'darkorange'</span><span class="token punctuation">,</span> lw<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'ROC curve ResNet-18 (area = %0.2f)'</span> <span class="token operator">%</span> roc_auc_resnet<span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>fpr_efficientnet<span class="token punctuation">,</span> tpr_efficientnet<span class="token punctuation">,</span> color<span class="token operator">=</span><span class="token string">'blue'</span><span class="token punctuation">,</span> lw<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'ROC curve EfficientNet-B0 (area = %0.2f)'</span> <span class="token operator">%</span> roc_auc_efficientnet<span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span>fpr_densenet<span class="token punctuation">,</span> tpr_densenet<span class="token punctuation">,</span> color<span class="token operator">=</span><span class="token string">'green'</span><span class="token punctuation">,</span> lw<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">'ROC curve DenseNet-121 (area = %0.2f)'</span> <span class="token operator">%</span> roc_auc_densenet<span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">,</span> color<span class="token operator">=</span><span class="token string">'navy'</span><span class="token punctuation">,</span> lw<span class="token operator">=</span><span class="token number">2</span><span class="token punctuation">,</span> linestyle<span class="token operator">=</span><span class="token string">'--'</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>xlim<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">1.0</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>ylim<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.0</span><span class="token punctuation">,</span> <span class="token number">1.05</span><span class="token punctuation">]</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'False Positive Rate'</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'True Positive Rate'</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span><span class="token string">'Receiver Operating Characteristic'</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span>loc<span class="token operator">=</span><span class="token string">"lower right"</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 绘制混淆矩阵</span><span class="token keyword">def</span> <span class="token function">plot_confusion_matrix</span><span class="token punctuation">(</span>y_true<span class="token punctuation">,</span> y_pred<span class="token punctuation">,</span> model_name<span class="token punctuation">)</span><span class="token punctuation">:</span>    cm <span class="token operator">=</span> confusion_matrix<span class="token punctuation">(</span>y_true<span class="token punctuation">,</span> y_pred<span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>figure<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">10</span><span class="token punctuation">,</span> <span class="token number">7</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    sns<span class="token punctuation">.</span>heatmap<span class="token punctuation">(</span>cm<span class="token punctuation">,</span> annot<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> fmt<span class="token operator">=</span><span class="token string">'d'</span><span class="token punctuation">,</span> cmap<span class="token operator">=</span><span class="token string">'Blues'</span><span class="token punctuation">,</span> xticklabels<span class="token operator">=</span>labels<span class="token punctuation">,</span> yticklabels<span class="token operator">=</span>labels<span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>xlabel<span class="token punctuation">(</span><span class="token string">'Predicted'</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>ylabel<span class="token punctuation">(</span><span class="token string">'Actual'</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>title<span class="token punctuation">(</span>f<span class="token string">'Confusion Matrix for &amp;#123;model_name&amp;#125;'</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token keyword">def</span> <span class="token function">plot_model_comparison</span><span class="token punctuation">(</span>y_true<span class="token punctuation">,</span> y_pred_resnet<span class="token punctuation">,</span> y_pred_efficientnet<span class="token punctuation">,</span> y_pred_densenet<span class="token punctuation">)</span><span class="token punctuation">:</span>    metrics <span class="token operator">=</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;</span>        <span class="token string">'Model'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token string">'Accuracy'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token string">'Precision'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token string">'Recall'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span>        <span class="token string">'F1 Score'</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>    <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#125;</span>    <span class="token keyword">for</span> model_name<span class="token punctuation">,</span> y_pred <span class="token keyword">in</span> zip<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token string">'ResNet-18'</span><span class="token punctuation">,</span> <span class="token string">'EfficientNet-B0'</span><span class="token punctuation">,</span> <span class="token string">'DenseNet-121'</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span>y_pred_resnet<span class="token punctuation">,</span> y_pred_efficientnet<span class="token punctuation">,</span> y_pred_densenet<span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">:</span>        metrics<span class="token punctuation">[</span><span class="token string">'Model'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span>model_name<span class="token punctuation">)</span>        metrics<span class="token punctuation">[</span><span class="token string">'Accuracy'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span>accuracy_score<span class="token punctuation">(</span>y_true<span class="token punctuation">,</span> y_pred<span class="token punctuation">)</span><span class="token punctuation">)</span>        metrics<span class="token punctuation">[</span><span class="token string">'Precision'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span>precision_score<span class="token punctuation">(</span>y_true<span class="token punctuation">,</span> y_pred<span class="token punctuation">,</span> average<span class="token operator">=</span><span class="token string">'macro'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        metrics<span class="token punctuation">[</span><span class="token string">'Recall'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span>recall_score<span class="token punctuation">(</span>y_true<span class="token punctuation">,</span> y_pred<span class="token punctuation">,</span> average<span class="token operator">=</span><span class="token string">'macro'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>        metrics<span class="token punctuation">[</span><span class="token string">'F1 Score'</span><span class="token punctuation">]</span><span class="token punctuation">.</span>append<span class="token punctuation">(</span>f1_score<span class="token punctuation">(</span>y_true<span class="token punctuation">,</span> y_pred<span class="token punctuation">,</span> average<span class="token operator">=</span><span class="token string">'macro'</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    metrics_df <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span>metrics<span class="token punctuation">)</span>    metrics_df<span class="token punctuation">.</span>set_index<span class="token punctuation">(</span><span class="token string">'Model'</span><span class="token punctuation">,</span> inplace<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 自定义颜色 (基于 #197196 的不同色调)</span>    colors <span class="token operator">=</span> <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#123;</span>        <span class="token string">'Accuracy'</span><span class="token punctuation">:</span> <span class="token string">'#003f5c'</span><span class="token punctuation">,</span>  # 深蓝色        <span class="token string">'Precision'</span><span class="token punctuation">:</span> <span class="token string">'#58508d'</span><span class="token punctuation">,</span>  # 深紫蓝色        <span class="token string">'Recall'</span><span class="token punctuation">:</span> <span class="token string">'#bc5090'</span><span class="token punctuation">,</span>  # 粉蓝色        <span class="token string">'F1 Score'</span><span class="token punctuation">:</span> <span class="token string">'#ff6361'</span>  # 明亮的红蓝色    <span class="token operator">&amp;</span><span class="token comment" spellcheck="true">#125;</span>        <span class="token comment" spellcheck="true"># 设置柱子的宽度和间隔</span>    bar_width <span class="token operator">=</span> <span class="token number">0.15</span>    gap <span class="token operator">=</span> <span class="token number">0.05</span>    num_metrics <span class="token operator">=</span> len<span class="token punctuation">(</span>metrics_df<span class="token punctuation">.</span>columns<span class="token punctuation">)</span>    num_models <span class="token operator">=</span> len<span class="token punctuation">(</span>metrics_df<span class="token punctuation">.</span>index<span class="token punctuation">)</span>        x <span class="token operator">=</span> range<span class="token punctuation">(</span>num_models<span class="token punctuation">)</span>    fig<span class="token punctuation">,</span> ax <span class="token operator">=</span> plt<span class="token punctuation">.</span>subplots<span class="token punctuation">(</span>figsize<span class="token operator">=</span><span class="token punctuation">(</span><span class="token number">14</span><span class="token punctuation">,</span> <span class="token number">8</span><span class="token punctuation">)</span><span class="token punctuation">)</span>    <span class="token keyword">for</span> idx<span class="token punctuation">,</span> metric <span class="token keyword">in</span> enumerate<span class="token punctuation">(</span>metrics_df<span class="token punctuation">.</span>columns<span class="token punctuation">)</span><span class="token punctuation">:</span>        <span class="token comment" spellcheck="true"># 计算每个柱子的位置</span>        offset <span class="token operator">=</span> <span class="token punctuation">(</span>bar_width <span class="token operator">+</span> gap<span class="token punctuation">)</span> <span class="token operator">*</span> <span class="token punctuation">(</span>idx <span class="token operator">-</span> num_metrics <span class="token operator">//</span> <span class="token number">2</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># Centering bars for each metric</span>        ax<span class="token punctuation">.</span>bar<span class="token punctuation">(</span>            <span class="token punctuation">[</span>p <span class="token operator">+</span> offset <span class="token keyword">for</span> p <span class="token keyword">in</span> x<span class="token punctuation">]</span><span class="token punctuation">,</span>             metrics_df<span class="token punctuation">[</span>metric<span class="token punctuation">]</span><span class="token punctuation">,</span>             bar_width<span class="token punctuation">,</span>             label<span class="token operator">=</span>metric<span class="token punctuation">,</span>            color<span class="token operator">=</span>colors<span class="token punctuation">[</span>metric<span class="token punctuation">]</span>        <span class="token punctuation">)</span>    <span class="token comment" spellcheck="true"># 设置标签和标题</span>    ax<span class="token punctuation">.</span>set_title<span class="token punctuation">(</span><span class="token string">'Model Comparison'</span><span class="token punctuation">)</span>    ax<span class="token punctuation">.</span>set_ylabel<span class="token punctuation">(</span><span class="token string">'Score'</span><span class="token punctuation">)</span>    ax<span class="token punctuation">.</span>set_xticks<span class="token punctuation">(</span>x<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># X轴刻度位置</span>    ax<span class="token punctuation">.</span>set_xticklabels<span class="token punctuation">(</span>metrics_df<span class="token punctuation">.</span>index<span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># X轴标签</span>    ax<span class="token punctuation">.</span>set_ylim<span class="token punctuation">(</span><span class="token number">0</span><span class="token punctuation">,</span> <span class="token number">1</span><span class="token punctuation">)</span>  <span class="token comment" spellcheck="true"># Y轴范围</span>    ax<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span>    plt<span class="token punctuation">.</span>show<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token comment" spellcheck="true"># 调用函数绘图</span>plot_roc_curve<span class="token punctuation">(</span>y_true<span class="token punctuation">,</span> y_pred_resnet<span class="token punctuation">,</span> y_pred_efficientnet<span class="token punctuation">,</span> y_pred_densenet<span class="token punctuation">)</span></code></pre><p>​<br><img src="https://volta-1309445959.cos.ap-beijing.myqcloud.com/blog/med_33_0.png" alt="png"><br>​    </p><pre class=" language-python"><code class="language-python">plot_confusion_matrix<span class="token punctuation">(</span>y_true<span class="token punctuation">,</span> y_pred_resnet<span class="token punctuation">,</span> <span class="token string">'ResNet-18'</span><span class="token punctuation">)</span>plot_confusion_matrix<span class="token punctuation">(</span>y_true<span class="token punctuation">,</span> y_pred_efficientnet<span class="token punctuation">,</span> <span class="token string">'EfficientNet-B0'</span><span class="token punctuation">)</span>plot_confusion_matrix<span class="token punctuation">(</span>y_true<span class="token punctuation">,</span> y_pred_densenet<span class="token punctuation">,</span> <span class="token string">'DenseNet-121'</span><span class="token punctuation">)</span></code></pre><p>​<br><img src="https://volta-1309445959.cos.ap-beijing.myqcloud.com/blog/med_34_0.png" alt="png"><br>​    </p><p><img src="https://volta-1309445959.cos.ap-beijing.myqcloud.com/blog/med_34_1.png" alt="png"></p><p><img src="https://volta-1309445959.cos.ap-beijing.myqcloud.com/blog/med_34_2.png" alt="png"></p><pre class=" language-python"><code class="language-python">plot_model_comparison<span class="token punctuation">(</span>y_true<span class="token punctuation">,</span> y_pred_resnet<span class="token punctuation">,</span> y_pred_efficientnet<span class="token punctuation">,</span> y_pred_densenet<span class="token punctuation">)</span></code></pre><p>​<br><img src="https://volta-1309445959.cos.ap-beijing.myqcloud.com/blog/med_35_0.png" alt="png"><br>​    </p>]]></content>
      
      
      <categories>
          
          <category> 深度学习 </category>
          
          <category> 实战项目 </category>
          
      </categories>
      
      
        <tags>
            
            <tag> 卷积神经网络 </tag>
            
        </tags>
      
    </entry>
    
    
    
    <entry>
      <title>Imitate_1_R&amp;B</title>
      <link href="/post/34260.html"/>
      <url>/post/34260.html</url>
      
        <content type="html"><![CDATA[<p>R&amp;B是一种源自于美国、和布鲁斯音乐较为相似的音乐形式。<br>R&amp;B is a Blues-like music 【form】（style), which comes from America.</p><p>区分限制性和非限制性定语从句<br>“—的”是限制性的，表达一种筛选。<br>非限制性表达一种补充<br><img src="https://volta-1309445959.cos.ap-beijing.myqcloud.com/blog/20240208113241.png" alt="image.png"></p><p>在中国，最具影响力的R&amp;B歌手是陶喆，如果不是因为陶将R&amp;B这种音乐形式在中国发扬光大，这片土地上的R&amp;B文化将会更加贫瘠。<br>The famous R&amp;B singer is TaoZhe who spreads R&amp;B （music form broad in) <em>musci form across</em>  China (where R&amp;B culture will become more barren).<em>,otherwise, the R&amp;B culture here would be far more barren.</em><br>&#x3D;&#x3D;David Tao, the most influential R&amp;B artist in China, has played a significant role in<br>popularizing this style in this land which would have otherwise been more barren in<br>terms of R&amp;B culture.&#x3D;&#x3D;</p><p>当县城的文化部门听到有传言说陶喆即将来这里开演唱会的时候，他们压根就没当真。<br>When rumors came into a (contry town relational department)<em>cultural department of the county town</em> that TaoZhe would come here to (held)<em>hold</em> a concert,they were not taken seriously.<br>&#x3D;&#x3D;When the news came to the cultural department of this small town that David<br>Tao was planning a concert in this small town, it was not taken seriously; however, as more evidence of David Tao’s arrival began to accumulate, the local cultural<br>department felt obliged to investigate, for the descriptions given by people who<br>claimed to have met David Tao a couple of days earlier in this town were<br>extraordinarily similar.&#x3D;&#x3D;</p><p>然而，随着相关证据越来越多，文化部门觉得有必要展开调查了，因为那些声称自己前几天就在本县亲眼见过陶的人所给出的描述都极 为相似。<br>However, as the evidence began to accumulate, the cultural department felt obliged to investigate, for the description given by people who claimed to have seen TaoZhe were extraordinarily similar.</p><p>调查工作是从一家快餐店开始的，当时快餐店的一名服务员听到了两位顾客在讨论陶喆要来开演唱会的事情。<br>The investigation began in a fast food shop where a waiter (listened that two customers were discussing that TaoZhe would hold a concert)<em>overheard two customers discussing Tao Zhe’s upcoming concert.</em>.<br>&#x3D;&#x3D;The investigation began in a fast-food store where a waiter in the store had overheard two customers talking about David Tao’s arrival for a concert in this town.&#x3D;&#x3D;<br>感官动词，非谓语做宾补</p><p>文化部门的官员认为，除非陶喆昏了头，否则是绝对不可能来这个小县城开演唱会的。<br>The offcial in the cultural department comfirmed that TaoZhe held a concert in this contry town impossibly unless he was stupid.<br>&#x3D;&#x3D;Officials from the local cultural department thought that it is impossible for David<br>Tao to come to this small county for a concert unless he has lost his mind&#x3D;&#x3D;</p><p>但事情没那么简单，调查工作也进展得很困难，因为经常有人说自己前两天亲眼见过陶喆，但详细问询之后，他们又改口说自己看走眼了。<br>(Something)<em>Things</em> were not <em>that</em> simple and investigation proved difficult,for some people said that they saw TaoZhe two days ago by themselves and that they made some mistakes after inquirying.<br>&#x3D;&#x3D;But things were not that simple, and the investigation proved difficult, for there<br>were often people who claimed to have seen David Tao a couple of days earlier but<br>backtracked saying they must have been mistaken upon detailed inquiry.&#x3D;&#x3D;</p><p>调查人员发现，似乎无论陶喆走到哪里，都会留下各种关于他的传说。在许多地方发现了陶喆留下的脚印，陶喆最经常穿的一件夹克还被人发现扔在了一家小吃店的椅子上。<br>Investigators found that whenever TaoZhe went, he left behind him some legend about him.Footprints from TaoZhe were seen in a number of places and a jacket (wearing)<em>worn</em> by TaoZhe usually was found <em>lying</em> on a chair in a food shop. <em>snack bar.</em></p><p>&#x3D;&#x3D;Investigators discovered that wherever David Tao goes, he leaves behind him a<br>whole lot of legends.Footprints left by David Tao were seen in a number of places and the jacket he most often wore was found lying on a chair in a snack shop.&#x3D;&#x3D;</p><p>既然本地人根本不可能穿这么好看的夹克，这件夹克必定是陶喆曾经穿过的那件。<br>As no local people had worn beautiful jackets , this jacket must had been in the possession of TaoZhe.<br>&#x3D;&#x3D;As the locals would never wear such a stylish jacket, this one must have been in<br>David Tao’s possession.&#x3D;&#x3D;</p><p>调查工作进行了好几天了，但始终未能发现陶喆的踪迹。<br>The investigation went on for several days, but TaoZhe was not found.<br>&#x3D;&#x3D;The investigation went on for quite a few days, but there was no sign of David<br>Tao’s presence.</p><p>对于陶喆的歌迷来说，一想到陶喆可能依旧在这个鸟不拉屎的地方闲逛，这真是令人担心。<br>It is disturbing for TaoZhe’s sing fans to think that TaoZhe is still hanging out in remote place.<br>&#x3D;&#x3D;For David Tao’s fans, it is disturbing to think that he is still wandering around in this<br>remote little town.</p>]]></content>
      
      
      <categories>
          
          <category> 英语学习 </category>
          
          <category> 新3 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Lesson_1_A Large Pumble</title>
      <link href="/post/64109.html"/>
      <url>/post/64109.html</url>
      
        <content type="html"><![CDATA[<h1 id="1-语法"><a href="#1-语法" class="headerlink" title="1. 语法"></a>1. 语法</h1><h2 id="1-1-限制性定语从句-vs-非限制性定语从句"><a href="#1-1-限制性定语从句-vs-非限制性定语从句" class="headerlink" title="1.1 限制性定语从句 vs 非限制性定语从句"></a>1.1 限制性定语从句 vs 非限制性定语从句</h2><ul><li>前者强调选择，强调定语部分。（筛选）</li><li>后者强调补充，强调名词性部分。</li><li><img src="https://volta-1309445959.cos.ap-beijing.myqcloud.com/blog/20240125134241.png" alt="image.png"><br>  <img src="https://volta-1309445959.cos.ap-beijing.myqcloud.com/blog/20240125134558.png" alt="image.png"></li></ul><h2 id="1-2-时态混用"><a href="#1-2-时态混用" class="headerlink" title="1.2 时态混用"></a>1.2 时态混用</h2><p>客观真理用现在时</p><h2 id="1-3-不太熟的系动词"><a href="#1-3-不太熟的系动词" class="headerlink" title="1.3 不太熟的系动词"></a>1.3 不太熟的系动词</h2><ol><li>feel</li><li>went——Things went worse.</li><li>stand——The mountain stands tall.</li><li>lie——Dishes are dirty in the sink.</li><li>fell—— The crowd fell silent.</li></ol><h2 id="1-4-At-vs-In-the"><a href="#1-4-At-vs-In-the" class="headerlink" title="1.4 At vs In the"></a>1.4 At vs In the</h2><ol><li><strong>In the evening</strong> 和 <strong>In the morning</strong>：<ul><li>这些短语用于描述发生在早晨或晚上的事情。”In the” 用于这样的时间段，强调的是在这个较长时间内的某个时刻。</li><li>例句：<ul><li>“I usually read the newspaper in the morning.”（我通常在早上阅读报纸。）</li><li>“We like to take a walk in the evening.”（我们喜欢在晚上散步。）</li></ul></li></ul></li><li><strong>At</strong>：<ul><li>“At” 通常用于具体的时间点，如 “at 5 o’clock”（在五点钟），”at midnight”（在午夜），”at noon”（在中午）”at night”。</li><li>例句：<ul><li>“The meeting starts at 9 a.m.”（会议在上午9点开始。）</li></ul></li></ul></li></ol><h2 id="1-5-补语vs状语"><a href="#1-5-补语vs状语" class="headerlink" title="1.5 补语vs状语"></a>1.5 补语vs状语</h2><p>I left the book there.(there 做补语 &#x3D; book is there)<br>It left trail of dead deer and small animals like rabbits &#x3D;&#x3D;behind it&#x3D;&#x3D; 做补语修饰trail。<br>It left &#x3D;&#x3D;behind it&#x3D;&#x3D;  trail of dead deer and small animals like rabbits </p><blockquote><p>补语太长，宾语太短，为保持句末中心，故提前补语<br>有时为了强调成分，也会提前部分内容（日他哥）<br><img src="https://volta-1309445959.cos.ap-beijing.myqcloud.com/blog/20240125142020.png" alt="image.png"></p></blockquote><p>ps：补语与被修饰部分构成A is B的关系</p><h2 id="1-6-prep"><a href="#1-6-prep" class="headerlink" title="1.6 prep"></a>1.6 prep</h2><p>“On the tree” 和 “up the tree” 在英语中有着不同的含义和用法，它们通常不能互换使用。</p><ol><li><strong>On the tree</strong>：<ul><li><strong>含义</strong>： “On the tree” 通常用来指某物附着在树的表面，比如树枝上或树干上。</li><li><strong>例句</strong>： “The bird built its nest on the tree.”（那只鸟在树上筑了巢。）</li></ul></li><li><strong>Up the tree</strong>：<ul><li><strong>含义</strong>： “Up the tree” 则通常用来描述某人或某物沿着树向上爬或已经爬到树的较高位置。</li><li><strong>例句</strong>： “The cat climbed up the tree to escape the dog.”（那只猫爬上树来逃避狗。）</li></ul></li></ol><h1 id="2-单词"><a href="#2-单词" class="headerlink" title="2. 单词"></a>2. 单词</h1><h2 id="At-large"><a href="#At-large" class="headerlink" title="At large"></a>At large</h2><p><strong>单词释义</strong>: “At large” 是一个短语，有几种不同的含义。它可以指：</p><ol><li><strong>自由的，未被捕获的</strong>：常用来描述逃犯或某个危险人物仍然自由行动，尚未被捕捉。</li><li><strong>整体上，普遍地</strong>：用来概括描述一个群体或整 体情况，而不是个别部分或个体。</li><li><strong>代表整体的</strong>：用于政治或组织背景中，指的是代表整个群体而不是特定选区或分支的成员。</li></ol><h2 id="Cornered"><a href="#Cornered" class="headerlink" title="Cornered"></a>Cornered</h2><p>“Cornered” 是一个英语动词的过去分词形式，它的基本含义是被逼入困境或陷入绝境，通常指某人或某物没有逃脱的余地，被迫面对危险或艰难的情况。下面是详细的释义、例句和发散性知识：</p><p><strong>释义</strong>：</p><ol><li>被逼入困境或陷入绝境，没有逃脱的余地。</li><li>遭受压力、危险或威胁，感到无法摆脱。</li></ol><p><strong>例句</strong>：</p><ol><li>The thief was cornered by the police in an alley and had no way to escape. （小偷被警察逼入了巷子里，无法逃脱。）</li><li>When faced with tough questions during the interview, the candidate felt cornered and struggled to answer. （在面试中遇到棘手的问题时，求职者感到陷入困境，难以回答。）</li><li>The company was cornered by financial difficulties and had to make some tough decisions to survive. （公司陷入了财务困境，不得不做出一些艰难的决策以生存下来。）</li></ol><p><strong>发散性知识</strong>：</p><ul><li>“Cornered” 这个词经常用于描述紧急或危险的情况，其中某人或某物似乎无法摆脱或逃离。这个词可以用在不同的上下文中，包括日常生活、商业、政治等领域，表示某人或某物感到被压迫或受到威胁。</li><li>“Backed into a corner” 是一个类似的表达，意思是某人被迫退到角落，面临严重的困境。这个表达通常用来形容某人在争论、竞争或危机中的处境。</li><li>这个词也可以用在比喻性的语境中，表示某人感到被迫采取行动或面对不愉快的局面，即使他们不愿意这么做。</li></ul><h1 id="3-回译"><a href="#3-回译" class="headerlink" title="3. 回译"></a>3. 回译</h1><h2 id="第一次"><a href="#第一次" class="headerlink" title="第一次"></a>第一次</h2><p>美洲狮是一种体形似猫的大动物，产于美洲。<br>Pumas are large, 【like-cats】（cat like)  animals which come from America.<br><em>Pumas are large, cat-like animals which are found in America.</em></p><p>当伦敦动物园接到报告说，在伦敦以南45英里处发现一只美洲狮时，这些报告并没有受到重视。<br>When these reports came into the London Zoo, they showed that a puma had 【】（been)  spotted 【at the southern fourty-five miles in】(forty-five miles south of) London which were not taken seriously.<br><em>When reports came into London Zoo &#x3D;&#x3D;that a wild puma had been spotted forty-five miles south of London&#x3D;&#x3D;, they were not taken seriously.</em></p><p>n修饰n 45英里的（伦敦的）南<br>同位语后置，end weight。</p><p>可是，随着证据越来越多，动物园的专家们感到有必要进行一番调查，因为凡是声称见到过美洲狮的人们所描述的情况竟是出奇地相似。<br>However, as 【evidences were】（evidence）  was gradully accumulated, the experts from the Zoo felt 【obligible】（obliged） to investigate 【】（，）for 【what people who claimed that they had seen pumas said】(the descriptions given by people who claimed to have seen the puma)  were similiar.<br>*However, as the evidence began to accumulate, experts from the Zoo felt obliged to investigate, for the descriptions &#x3D;&#x3D;given by people who claimed to have seen the puma&#x3D;&#x3D; were extraordinarily similar.</p><p>搜寻美洲狮的工作是从一座小村庄开始的。那里的一位妇女在采摘黑莓时的看见“一只大猫”，离她仅5码远，她刚看见它，它就立刻逃走了。专家证实，美洲狮非被逼得走投无路，是决不会伤人的。<br>The hunt 【searching】（for)  pumas started in 【】（a）town where 【the】（a） woman saw “a large cat”  when she was picking strawberries. Once she glanced it, it imediately ran away.The experts 【proved】（confirmed） that pumas will not hurt human beings unless they are cornered.<br><em>The hunt for the puma began in a small village where a woman picking blackberries saw ‘a large cat’ only five yards away from her.It immediately ran away when she saw it, and experts confirmed that a puma will not attack a human being unless it is cornered.</em></p><p>事实上搜寻工作很困难，因为常常是早晨在甲地发现那只美洲狮，晚上却在20英里外的乙地发现它的踪迹。<br>Actually, （The search proved）  【searching hunt was】   so difficult （，）for the puma was found at 【a】(one) place 【at morning】（in the morning） and 【it was found】 at another place 【at evening】（ twenty miles away in the evening）.<br>*The search proved difficult, for the puma was often observed at one place in the morning and at another place twenty miles away in the evening.</p><p>无论它走哪儿，一路上总会留下一串死鹿及死兔子之类的小动物，在许多地方看见爪印，灌木丛中发现了粘在上面的美洲狮毛。<br>Wherever it walked, a trail of some dead deers and rabbits were left  behind it.Paw（prints）could be seen （in a number of places）and （puma）【furs were】（fur was）  found clinging to branches.<br><em>Wherever it went, it left &#x3D;&#x3D;behind it&#x3D;&#x3D; a trail of dead deer and small animals like rabbits.Paw prints were seen in a number of places and puma fur was found clinging to bushes.</em><br>补语提前</p><p>有人抱怨说夜里听见“像猫一样的叫声”；一位商人去钓鱼，看见那只美洲狮在树上。<br>Someone complained （of hearing a cat-like noise at night） 【that they could listen voice like cat】; a businessman (on a fishing trip) 【fishing】 saw the puma on the tree.<br><em>Several people complained of “cat-like noises’ at night and a businessman on a fishing trip saw the puma up a tree.</em></p><p>专家们如今已经完全肯定那只动物就是美洲狮，但它是从哪儿来的呢？<br>The experts （had now fully） confirmed that the animal is puma, but where had it come from ?<br><em>The experts were now fully convinced that the animal was a puma, but where had it come from?</em></p><p>由于全国动物园没有一家报告丢了美洲狮，因此那只美洲狮一定是某位私人收藏豢养的，不知怎么设法逃出来了。<br>No 【any】 zoo reported that they lost a puma.Therefore that puma must (have) be in the possession of (a) private collected man and somehow 【it】 managed to escape.<br><em>As no pumas had been reported missing from any zoo in the country, this one must have been in the possession of a private collector and somehow managed to escape.</em><br>将 “No any zoo reported that they losed a puma” 改为 “No zoo reported losing a puma” 是因为原句在语法和用词上有几个错误，而修改后的句子则更加符合英语的标准语法规则。让我们一一分析这些错误和改正：</p><ol><li><strong>使用 “any” 的错误</strong>：<ul><li>原句中的 “No any zoo” 是不正确的。在英语中，当使用 “no” 作为否定词时，不需要再加 “any”。正确的表达方式是 “No zoo”。</li></ul></li><li><strong>动词形式的错误</strong>：<ul><li>“Losed” 并不是 “lose” 的正确过去式。正确的过去式是 “lost”。然而，在这个句子中，使用 “losing”（现在分词形式）更加合适，因为它与 “reported”（过去时态）结合，形成了一个更流畅、更自然的表达方式。</li></ul></li></ol><p>搜寻工作进行了好几个星期，但始终未能逮住那只美洲狮。想到在宁静的乡村里有一头危险的野兽继续逍遥流窜，真令人担心。<br>The search lasted several weeks, but that puma was not caught. It is 【disturbed】（disturbing to think） that a dangerous wild animal【s】 is still at large in 【the】quiet countryside.<br><em>The hunt went on for several weeks, but the puma was not caught. It is disturbing to think that a dangerous wild animal is still at large in the quiet countryside.</em></p><p>问题1<br>原文：The search proved difficult, for the puma was often observed at one place in the morning and at another place twenty miles away in the evening.</p><p>这at another place twenty miles away是副词型成分，at another place很好理解，但twenty miles away感觉很诡异，为什么是n+prep？<br>难道是away twenty miles 倒装了吗？<br>还是说是应该写成at twenty miles away another place，只不过不这么写？<br>还是说是at another place twenty miles away （from another place） 省略了后面？就像only five yards away from her？</p><p>类似这些数词的用法，在阅读过程中常能见到，但是理解对的很少，今天自己做回译发现完全写不出来甚至牛头不对马嘴。Larry哥觉得有必要出一节数词+成分的解析吗？</p><p>问题2<br>  last &#x3D; last for吗？<br>  问了gpt他的回答是（以防万一还是问问Larry哥）：<br>“The hunt went on for several weeks” 这个句子可以使用 “last” 或 “last for” 来改写，但两者在结构上有所不同。下面是改写的两种正确方式：</p><ol><li>**使用 “last”**：<ul><li>句子可以改为 “The hunt lasted several weeks.” 在这里，”lasted” 是动词 “last” 的过去式，直接后接时间段 “several weeks”。这种结构是正确的，意思是狩猎持续了几周时间。</li></ul></li><li>**使用 “last for”**：<ul><li>另一种表达方式是 “The hunt did last for several weeks.” 在这里，”did last for” 是强调结构，用 “did” 来强调动词 “last”。这个句子结构也是正确的，同样表达了狩猎持续了几周的意思。</li></ul></li></ol><p>两种表达方式都是语法正确的，但它们在语气上略有不同。”The hunt lasted several weeks” 是更常见和直接的表达，而 “The hunt did last for several weeks” 则在语气上稍微强调了时间的持续性。选择哪种表达取决于你想要传达的具体语气和上下文环境。</p><p>问题3<br>as the evidence began to accumulate随着证据越来越多<br>证据不应该是被积累么？我写的是：as evidence was gradully accumulated(以及这里不加the可以吗？加不加the太难了)<br>哪怕是按照原文的写法，我的想法是使用as the evidence began to be accumulated<br>抛给gpt他没检测出这个位置的问题。说俩种都行，我感觉证据积累就有点不怎么对。</p>]]></content>
      
      
      <categories>
          
          <category> 英语学习 </category>
          
          <category> 新3 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>Lesson_2_Thirteen equals one</title>
      <link href="/post/28518.html"/>
      <url>/post/28518.html</url>
      
        <content type="html"><![CDATA[<h1 id="1-语法"><a href="#1-语法" class="headerlink" title="1. 语法"></a>1. 语法</h1><h2 id="1-1-固定"><a href="#1-1-固定" class="headerlink" title="1.1 固定"></a>1.1 固定</h2><p>使役动词make&#x2F;let&#x2F;have +sb&#x2F;sth + 【宾补：（to） do&#x2F;doing&#x2F;done】<br>省略to，去掉不确定的含义。</p><ol><li>人作为主语，动词不定式做宾补</li></ol><ul><li>I had you do this job. ——命令做</li><li>We are so glad to have Larry spend the day with us.——非主观意愿发生的与自己有关的事。<br>ps：一坏一好</li></ul><ol start="2"><li>人做主语+现在分词做宾补</li></ol><ul><li>I had you laughing.——我逗笑你了（主动逗笑）<br>ps: 好！</li></ul><ol start="3"><li>人做主语+过去分词宾补</li></ol><ul><li>I had my car washed.——我（让别人）把车给洗了</li><li>I had my car stolen.——我（让别人）把车给偷了<br>总结——省略了by sb（可好可坏）</li></ul><ol start="4"><li>事物主语+现在分词宾补</li></ol><ul><li>This thing had me longing for my school days.——某事物造成某局面。（可好可坏）</li></ul><ol start="5"><li>事物主语+过去宾补</li></ol><ul><li>This thing had its name known by all people.——无意造成某种有利局面。</li></ul><p>make&#x2F;let&#x2F;have sb do sth 命令某人做某事</p><p>have&#x2F;get sth done 完成某事</p>]]></content>
      
      
      <categories>
          
          <category> 英语学习 </category>
          
          <category> 新3 </category>
          
      </categories>
      
      
    </entry>
    
    
    
    <entry>
      <title>回译练习方法</title>
      <link href="/post/54812.html"/>
      <url>/post/54812.html</url>
      
        <content type="html"><![CDATA[<p>你现在要做的是，对照着这份教材提供的中文译文，把它翻译回英文，这就是所谓的回译。这份翻译你做得好，就说明你此前的学习过程执行得很到位，如果做得不好，就说明你此前的学习漏洞太多了，必须重新学！  </p><p>        你肯定对此还有一些疑问，你的疑问都有哪些，我也能预测得到，接下来我给大家一一解答一下。</p><p><strong>Q1：****如果我翻译出来的版本和课文原文不一样怎么办？是不是说明我的学习不够到位呢？</strong>  </p><p>A1：<strong>你回译出来的东西并不需要和原文一模一样</strong>，或者说，不一样才是正常的。即便你翻译出来的东西和原文不一样，也并不代表你的翻译就一定错了，这个时候，你可以用chatGPT、翻译软件、或者其他的AI产品来检验你的译文是否有问题。</p><p>如果chatGPT认为你的译文有问题，且你的译文又和课文原文不一样，那意味着你的翻译必然是有问题的。chatGPT在回答复杂语法问题的时候的确会翻车，但在检验你给出的语料是否符合英文的行文规范方面，它是不会翻车的，所以，【chatGPT认为你有问题 + 你的翻译和课文原文不一致】，这种情况下，你就需要去详细分析你的译文了，你需要查字典、google、继续用其他的prompt询问chatGPT，等等等等，直到把你的问题解决掉为止。  </p><p>PS，零起点级别的学习者做的回译，往往和课文原文高度一致，因为这个阶段的学习者脑子里是空的，除了刚刚学过的课文之外，他们脑子里没有更多的语料储备，所以，零起点的学习者做回译的时候，要么写出和原文一样的句子，要么就会写病句。但有一定基础的学习者就不一样了，因为脑子里有一定的语料储备，做回译的时候是必然会造出和原文不一样的句子的。  </p><p><strong>Q2：我需要把课文原文背下来吗？</strong></p><p>A2：<strong>当然不需要，你没必要刻意去背</strong>，如果在回译的过程中，你对课文原文的记忆仍未消退，你写出来的句子和原文相似度极高，甚至写出了一模一样的句子，这都属于正常现象，你用不着因为自己不小心把原文给“背”下来了，就认为自己的回译过程失败了。</p><p>你需要记住的是，你用不着刻意去背，但如果你不小心“背”下来了，也完全无所谓，这并不重要，因为只要你没有刻意去背，你写出来和原文一模一样的句子，只意味着一件事：你的输出能力已经进步了。  </p><p>**Q3：我应该学完一篇课文后马上开始做回译吗？<br>**</p><p>A3：如果你学习的课文有一定难度，学完课文后马上开始回译是没有问题的，就比如<A puma at large>好了，这种稍有难度的文章，除非刻意去背，否则你是不可能完整地记忆下来的，这种情况下，学习完之后立即执行回译是没有问题的。</p><p>如果相对你的水平来说，你学习的目标文章难度很低，比如，作为一名大学生，你看了一篇新概念一的文章，你看完之后直接做回译的话，因为文章难度太低，结果就是你会很自然地把原文给“背”下来，这个时候，你可以迟一点做回译，比如，等看完文章的一个小时之后，再开始回译。  </p><p><strong>回译的精髓就是在一种【记了一半、忘了一半】的情况下进行输出，这样做的意义在于，它会让你的输出活动变得更容易，让一切更容易把控。</strong>如果让你写一篇essay来锻炼输出水平，结果大概率是你憋了半天，一个字都憋不出来，这就失去了练习的意义；如果让你翻译一篇陌生的文章，你还是一个字都翻译不出来，因为你的水平达不到，这同样没有意义。回译不一样，回译的时候，你的状态是【记了一半、忘了一半】，你无需担心“不知道该写什么”这种情况。</p><p>回译的过程，就是不停回想原文的过程，这会加深你对原文的理解，以及，你也必然会遇到无论如何都回想不起原文内容的情况，于是你只好自己去造和原文不一样的句子，你造出来的句子大概率和原文是“亲戚”，这同样是好事，这个过程同样加深了你对原文的理解，即便这些“亲戚”中会出现病句，也完全无伤大雅，解决这些病句的过程，将会极大提升你的写作能力！  </p><p>**Q4：回译做一遍够吗？需不需要多做几遍 **</p><p>A4：我个人推荐你至少做两遍，因为一遍或许不够扎实，当然了，如果你使用的材料难度不大，比如你用的是新概念二，那么一遍也没问题，这个问题并没有标准答案，你需要根据自己的实际情况来灵活掌握。</p><p>我严重建议你在“时过境迁”之后，尝试回译此前已经学习过的课文，比如，你两个月之前已经学习过<A puma at large>这篇课文了，当时也做了回译了，如果你能此时此刻再拿出来重新做一遍回译，相信我，你的收获会无比巨大！  </p><p>        上面这四条是大家最经常问的一些有关回译执行方面的问题，我刚刚也都给大家详细解答了，大家需要知道的是，除了回译，你找不到第二种能够完美检验你学习成果的方式，很多参加了训练营的同学纷纷跟我感叹道：<strong>做了回译我才知道，原来自己英语这么烂…</strong></p><p>        没错，做了回译，你才会知道自己身上的漏洞原来这么多！为什么会这样？原因很简单，回译是真正的“下海游泳”，这是真正硬核的学习方式，而其他的练习方式，比如做几个选择题，做几个填空题，不过是“泳池戏水”的小儿科而已，<strong>回译固然是较为严苛的学习方式，但不如此，你就无法提升自己的语法和写作水平，既然考研需要写作，四六级需要写作，托福雅思也需要写作，而回译又的确能提升你的写作能力，你为什么不练？</strong></p>]]></content>
      
      
      <categories>
          
          <category> 英语学习 </category>
          
          <category> 方法 </category>
          
      </categories>
      
      
    </entry>
    
    
  
  
</search>
